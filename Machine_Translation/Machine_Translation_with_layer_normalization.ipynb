{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "DL_HW4_part3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccUe6CjkfzO1"
      },
      "source": [
        "# import data and libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjPmwllYfwKY"
      },
      "source": [
        "- download data from google drive to kaggle \n",
        "- unzip data\n",
        "- upgrade torch, torchtext, torchvision and nltk libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-06-30T13:57:24.977287Z",
          "iopub.execute_input": "2021-06-30T13:57:24.977567Z",
          "iopub.status.idle": "2021-06-30T13:57:24.982727Z",
          "shell.execute_reply.started": "2021-06-30T13:57:24.977541Z",
          "shell.execute_reply": "2021-06-30T13:57:24.981537Z"
        },
        "trusted": true,
        "id": "68AREOLJZKWj"
      },
      "source": [
        "### This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:57:25.690583Z",
          "iopub.execute_input": "2021-06-30T13:57:25.690930Z",
          "iopub.status.idle": "2021-06-30T13:57:31.673048Z",
          "shell.execute_reply.started": "2021-06-30T13:57:25.690897Z",
          "shell.execute_reply": "2021-06-30T13:57:31.672017Z"
        },
        "trusted": true,
        "id": "Y02cNABxZKWp"
      },
      "source": [
        "! pip install -q gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tF-HKFasZKWp"
      },
      "source": [
        "! gdown 'https://drive.google.com/u/0/uc?id=1AoiQCXqFbqETGILCpgFgozYJvmyGfq_9&export=download'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9piD5S4_ZKWq"
      },
      "source": [
        "! gdown 'https://drive.google.com/u/0/uc?id=1zmdERncg0zcrqpdCzOzth0exYevXxEp2&export=download'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IVB7_FnqZKWq"
      },
      "source": [
        "! unzip './AFEC-merged-all.zip'\n",
        "!unzip './Test.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:57:48.975282Z",
          "iopub.execute_input": "2021-06-30T13:57:48.975621Z",
          "iopub.status.idle": "2021-06-30T13:57:54.834497Z",
          "shell.execute_reply.started": "2021-06-30T13:57:48.975583Z",
          "shell.execute_reply": "2021-06-30T13:57:54.833445Z"
        },
        "trusted": true,
        "id": "wAT7MZCHZKWr"
      },
      "source": [
        "! pip install -q pyonmttok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:57:54.836139Z",
          "iopub.execute_input": "2021-06-30T13:57:54.836472Z",
          "iopub.status.idle": "2021-06-30T13:58:00.697330Z",
          "shell.execute_reply.started": "2021-06-30T13:57:54.836443Z",
          "shell.execute_reply": "2021-06-30T13:58:00.696374Z"
        },
        "trusted": true,
        "id": "wEtcYDCPZKWr",
        "outputId": "de1fe99c-f96c-4ede-bb43-4cf0e15c59a5"
      },
      "source": [
        "! pip install --upgrade nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.6.2)\n",
            "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk) (2021.3.17)\n",
            "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.59.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:00.701272Z",
          "iopub.execute_input": "2021-06-30T13:58:00.701566Z",
          "iopub.status.idle": "2021-06-30T13:58:06.728153Z",
          "shell.execute_reply.started": "2021-06-30T13:58:00.701539Z",
          "shell.execute_reply": "2021-06-30T13:58:06.727250Z"
        },
        "trusted": true,
        "id": "25wyp_-wZKWt",
        "outputId": "ad91788c-fa0e-4e97-dd46-0c441a148c58"
      },
      "source": [
        "pip install --upgrade torchtext"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchtext in /opt/conda/lib/python3.7/site-packages (0.10.0)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torchtext) (4.59.0)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied: torch==1.9.0 in /opt/conda/lib/python3.7/site-packages (from torchtext) (1.9.0)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchtext) (2.25.1)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (1.26.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->torchtext) (4.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:06.730199Z",
          "iopub.execute_input": "2021-06-30T13:58:06.730544Z",
          "iopub.status.idle": "2021-06-30T13:58:12.705329Z",
          "shell.execute_reply.started": "2021-06-30T13:58:06.730504Z",
          "shell.execute_reply": "2021-06-30T13:58:12.704390Z"
        },
        "trusted": true,
        "id": "E59mV7lUZKWu",
        "outputId": "16322559-ed2c-4651-ea7c-6db93b1f7458"
      },
      "source": [
        "pip install --upgrade torch torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.9.0)\n",
            "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.10.0)\n",
            "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (7.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDZZIHYTftCx"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIrCfBs7fpsD"
      },
      "source": [
        "- read data line by line\n",
        "- create a pandas data frame\n",
        "- split data to train (90%) and validation (10%)\n",
        "- save train and validation data frames\n",
        "\n",
        "> with help of this [tutorail](https://youtu.be/DaHAzCaXWYQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:12.709215Z",
          "iopub.execute_input": "2021-06-30T13:58:12.709555Z",
          "iopub.status.idle": "2021-06-30T13:58:13.568754Z",
          "shell.execute_reply.started": "2021-06-30T13:58:12.709519Z",
          "shell.execute_reply": "2021-06-30T13:58:13.567859Z"
        },
        "trusted": true,
        "id": "hU5yVt3sZKWv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:13.570056Z",
          "iopub.execute_input": "2021-06-30T13:58:13.570438Z",
          "iopub.status.idle": "2021-06-30T13:58:15.416974Z",
          "shell.execute_reply.started": "2021-06-30T13:58:13.570402Z",
          "shell.execute_reply": "2021-06-30T13:58:15.416077Z"
        },
        "trusted": true,
        "id": "obU0sV2QZKWw"
      },
      "source": [
        "text_fa = open('./AFEC-merged.fa', encoding='utf8').read().splitlines()\n",
        "text_eng =  open('./AFEC-merged.en', encoding='utf8').read().splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:15.418255Z",
          "iopub.execute_input": "2021-06-30T13:58:15.418636Z",
          "iopub.status.idle": "2021-06-30T13:58:15.423560Z",
          "shell.execute_reply.started": "2021-06-30T13:58:15.418585Z",
          "shell.execute_reply": "2021-06-30T13:58:15.422344Z"
        },
        "trusted": true,
        "id": "piC_Jkf6ZKWw"
      },
      "source": [
        "persian_english_text = {'English':text_eng, 'Persian':text_fa}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:15.426304Z",
          "iopub.execute_input": "2021-06-30T13:58:15.426728Z",
          "iopub.status.idle": "2021-06-30T13:58:15.890772Z",
          "shell.execute_reply.started": "2021-06-30T13:58:15.426689Z",
          "shell.execute_reply": "2021-06-30T13:58:15.889786Z"
        },
        "trusted": true,
        "id": "xKXVXxH1ZKWx",
        "outputId": "cf132338-1b73-40ea-a617-715dea8e8ab6"
      },
      "source": [
        "df =pd.DataFrame(persian_english_text, columns=['English', 'Persian'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  English  \\\n",
              "0       North Waziristan operation kills 50 more milit...   \n",
              "1       PESHAWAR - The on - goingmilitary operation in...   \n",
              "2       The Pakistani Air Force conducted airstrikes a...   \n",
              "3       A day earlier , at least 27 militants were rep...   \n",
              "4       Meanwhile , a roadside blast on Bangidar road ...   \n",
              "...                                                   ...   \n",
              "684412  that is an excellent idea . when is your birth...   \n",
              "684413  fine , then we will go back by train to Hambur...   \n",
              "684414  well , I think , eight o ' clock in the evenin...   \n",
              "684415  there is a train at thirty-three past six o ' ...   \n",
              "684416                                         goodbye .    \n",
              "\n",
              "                                                  Persian  \n",
              "0          مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی  \n",
              "1       پیشاور - به گزارش جیو نیوز , عملیات ادامه دار ...  \n",
              "2       به گزارش رسانه‌ها , نیروی هوایی پاکستان حملات ...  \n",
              "3       یک روز پیشتر گزارش شده بود که دست کم 27 ستیزه ...  \n",
              "4       در ضمن , مسئولان گفتند که یک انفجار کنارجاده ا...  \n",
              "...                                                   ...  \n",
              "684412           این یک فکر عالی است . تولد شما کی است ?   \n",
              "684413  خوب , بنابراین ما با قطار در سه و سی و سه دقیق...  \n",
              "684414  خوب , من فکر میکنم , ساعت هشت بعداز ظهر کافی ا...  \n",
              "684415  یک قطار برای ساعت شش و سی و سه دقیقه وجود دارد...  \n",
              "684416                                         خداحافظ .   \n",
              "\n",
              "[684417 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Persian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North Waziristan operation kills 50 more milit...</td>\n",
              "      <td>مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PESHAWAR - The on - goingmilitary operation in...</td>\n",
              "      <td>پیشاور - به گزارش جیو نیوز , عملیات ادامه دار ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Pakistani Air Force conducted airstrikes a...</td>\n",
              "      <td>به گزارش رسانه‌ها , نیروی هوایی پاکستان حملات ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A day earlier , at least 27 militants were rep...</td>\n",
              "      <td>یک روز پیشتر گزارش شده بود که دست کم 27 ستیزه ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Meanwhile , a roadside blast on Bangidar road ...</td>\n",
              "      <td>در ضمن , مسئولان گفتند که یک انفجار کنارجاده ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684412</th>\n",
              "      <td>that is an excellent idea . when is your birth...</td>\n",
              "      <td>این یک فکر عالی است . تولد شما کی است ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684413</th>\n",
              "      <td>fine , then we will go back by train to Hambur...</td>\n",
              "      <td>خوب , بنابراین ما با قطار در سه و سی و سه دقیق...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684414</th>\n",
              "      <td>well , I think , eight o ' clock in the evenin...</td>\n",
              "      <td>خوب , من فکر میکنم , ساعت هشت بعداز ظهر کافی ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684415</th>\n",
              "      <td>there is a train at thirty-three past six o ' ...</td>\n",
              "      <td>یک قطار برای ساعت شش و سی و سه دقیقه وجود دارد...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684416</th>\n",
              "      <td>goodbye .</td>\n",
              "      <td>خداحافظ .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>684417 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:15.892532Z",
          "iopub.execute_input": "2021-06-30T13:58:15.892895Z",
          "iopub.status.idle": "2021-06-30T13:58:16.164415Z",
          "shell.execute_reply.started": "2021-06-30T13:58:15.892858Z",
          "shell.execute_reply": "2021-06-30T13:58:16.163549Z"
        },
        "trusted": true,
        "id": "vHbnAKJPZKWz"
      },
      "source": [
        "train, validation = train_test_split(df, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:16.165670Z",
          "iopub.execute_input": "2021-06-30T13:58:16.166187Z",
          "iopub.status.idle": "2021-06-30T13:58:24.442021Z",
          "shell.execute_reply.started": "2021-06-30T13:58:16.166134Z",
          "shell.execute_reply": "2021-06-30T13:58:24.441158Z"
        },
        "trusted": true,
        "id": "nEgDhLqaZKWz"
      },
      "source": [
        "train.to_csv('train.csv', index=False)\n",
        "validation.to_csv('validation.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OFC58kNfktn"
      },
      "source": [
        "\n",
        "\n",
        "# Create dataset and dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mvSomX8fdpP"
      },
      "source": [
        "- create persian and english tokenizer functions\n",
        "- create 2 Field for persian and english\n",
        "- create training and validation data from train and validation data frames\n",
        "- build vocabulary for 2 langages with frequency threshold of 5 and maximum size of 20000\n",
        "- craete train and validation data loaders with batch size of 64\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> with help of this [tutorail](https://youtu.be/DaHAzCaXWYQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:24.443263Z",
          "iopub.execute_input": "2021-06-30T13:58:24.443611Z",
          "iopub.status.idle": "2021-06-30T13:58:24.897130Z",
          "shell.execute_reply.started": "2021-06-30T13:58:24.443576Z",
          "shell.execute_reply": "2021-06-30T13:58:24.896179Z"
        },
        "trusted": true,
        "id": "UdL0dmykZKW0",
        "outputId": "7a2c7a4b-692d-41c9-b66c-f093861450d7"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:24.906522Z",
          "iopub.execute_input": "2021-06-30T13:58:24.906869Z",
          "iopub.status.idle": "2021-06-30T13:58:24.918997Z",
          "shell.execute_reply.started": "2021-06-30T13:58:24.906835Z",
          "shell.execute_reply": "2021-06-30T13:58:24.918190Z"
        },
        "trusted": true,
        "id": "SPbwbF43ZKW1"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:24.898588Z",
          "iopub.execute_input": "2021-06-30T13:58:24.898936Z",
          "iopub.status.idle": "2021-06-30T13:58:24.905099Z",
          "shell.execute_reply.started": "2021-06-30T13:58:24.898897Z",
          "shell.execute_reply": "2021-06-30T13:58:24.903722Z"
        },
        "trusted": true,
        "id": "Nz_VPOHMZKW1"
      },
      "source": [
        "def tokenizer_fa(text):\n",
        "  text = re.sub(\"(\\\\u200c|\\\\xad)\", \" \", text)\n",
        "  return nltk.word_tokenize(text)\n",
        "def tokenizer_eng(text):\n",
        "  return [token.lower() for token in nltk.word_tokenize(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:24.920454Z",
          "iopub.execute_input": "2021-06-30T13:58:24.920853Z",
          "iopub.status.idle": "2021-06-30T13:58:24.928495Z",
          "shell.execute_reply.started": "2021-06-30T13:58:24.920799Z",
          "shell.execute_reply": "2021-06-30T13:58:24.927640Z"
        },
        "trusted": true,
        "id": "RhAd6EUNZKW2"
      },
      "source": [
        "english = Field(sequential=True, use_vocab=True, tokenize=tokenizer_eng, lower=True, init_token='<SOS>', eos_token='<EOS>', batch_first=True)\n",
        "persian = Field(sequential=True, use_vocab=True, tokenize=tokenizer_fa, init_token='<SOS>', eos_token='<EOS>',  batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:24.929952Z",
          "iopub.execute_input": "2021-06-30T13:58:24.930348Z",
          "iopub.status.idle": "2021-06-30T13:58:24.938102Z",
          "shell.execute_reply.started": "2021-06-30T13:58:24.930306Z",
          "shell.execute_reply": "2021-06-30T13:58:24.937245Z"
        },
        "trusted": true,
        "id": "ABQDYachZKW2"
      },
      "source": [
        "fields = {'English':('eng', english), 'Persian':('fa', persian)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:58:24.940049Z",
          "iopub.execute_input": "2021-06-30T13:58:24.940461Z",
          "iopub.status.idle": "2021-06-30T14:04:46.796011Z",
          "shell.execute_reply.started": "2021-06-30T13:58:24.940407Z",
          "shell.execute_reply": "2021-06-30T14:04:46.795138Z"
        },
        "trusted": true,
        "id": "LXMP-jq4ZKW3"
      },
      "source": [
        "train_data, validation_data = TabularDataset.splits(\n",
        "    path='',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format='csv',\n",
        "    fields=fields\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:46.797534Z",
          "iopub.execute_input": "2021-06-30T14:04:46.797905Z",
          "iopub.status.idle": "2021-06-30T14:04:55.846769Z",
          "shell.execute_reply.started": "2021-06-30T14:04:46.797867Z",
          "shell.execute_reply": "2021-06-30T14:04:55.845875Z"
        },
        "trusted": true,
        "id": "9lIbqhwJZKW3"
      },
      "source": [
        "english.build_vocab(train_data,max_size= 20000, min_freq=5)\n",
        "persian.build_vocab(train_data,max_size= 20000, min_freq=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.848553Z",
          "iopub.execute_input": "2021-06-30T14:04:55.848994Z",
          "iopub.status.idle": "2021-06-30T14:04:55.856333Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.848948Z",
          "shell.execute_reply": "2021-06-30T14:04:55.855484Z"
        },
        "trusted": true,
        "id": "Uq1xV8zdZKW4"
      },
      "source": [
        "train_iterator, validation_iterator = BucketIterator.splits(\n",
        "    (train_data, validation_data),\n",
        "    batch_size=64,\n",
        "    sort=False,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmuiGKO3fN28"
      },
      "source": [
        "# Create Model\n",
        "- define positional encoding, word embedding, position wise feedforward, multihead attention modules\n",
        "- create encoder layer\n",
        "- create encoder cosist of multiple encoder layers\n",
        "- create decoder cosist of multiple decoder layers usinf torch modules\n",
        "- create transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.858121Z",
          "iopub.execute_input": "2021-06-30T14:04:55.858607Z",
          "iopub.status.idle": "2021-06-30T14:04:55.908424Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.858568Z",
          "shell.execute_reply": "2021-06-30T14:04:55.907365Z"
        },
        "trusted": true,
        "id": "p_5ogbHgZKW4"
      },
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import  torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import math\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC53G_0AfKJ0"
      },
      "source": [
        "## positional encoding\n",
        "- embedding size of 256\n",
        "- dropout rate = 0.1\n",
        "- max length of positional encoding tensor = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.909894Z",
          "iopub.execute_input": "2021-06-30T14:04:55.910421Z",
          "iopub.status.idle": "2021-06-30T14:04:55.922243Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.910380Z",
          "shell.execute_reply": "2021-06-30T14:04:55.921434Z"
        },
        "trusted": true,
        "id": "r_vPhGstZKW5"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 200):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        # sum of tokekn embeding and positional encoding\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYFvC_fLfGGs"
      },
      "source": [
        "## Embedding\n",
        "- map word vectors to embedding with size of 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.923562Z",
          "iopub.execute_input": "2021-06-30T14:04:55.924150Z",
          "iopub.status.idle": "2021-06-30T14:04:55.933952Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.924108Z",
          "shell.execute_reply": "2021-06-30T14:04:55.933153Z"
        },
        "trusted": true,
        "id": "EoXOeDThZKW6"
      },
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        # token embedding * scale\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGJtfUhefBwF"
      },
      "source": [
        "## position wise feed forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.935330Z",
          "iopub.execute_input": "2021-06-30T14:04:55.935726Z",
          "iopub.status.idle": "2021-06-30T14:04:55.944318Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.935687Z",
          "shell.execute_reply": "2021-06-30T14:04:55.943523Z"
        },
        "trusted": true,
        "id": "ybh8fbD_ZKW6"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x): \n",
        "        x = self.dropout(torch.relu(self.fc_1(x))) # (batch size, seq len, hid dim)\n",
        "        x = self.fc_2(x) # (batch size, seq len, pf dim)\n",
        "        return x # (batch size, seq len, hid dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuqkkMnSe9mC"
      },
      "source": [
        "## Multihead attention\n",
        "- calculate attention by scaled dot product using key, value and Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.947429Z",
          "iopub.execute_input": "2021-06-30T14:04:55.947956Z",
          "iopub.status.idle": "2021-06-30T14:04:55.961493Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.947916Z",
          "shell.execute_reply": "2021-06-30T14:04:55.960515Z"
        },
        "trusted": true,
        "id": "_HVEvCUWZKW7"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        #assert hid_dim % n_heads == 0\n",
        "        self.hid_dim = hid_dim # embedding size or d_model\n",
        "        self.n_heads = n_heads  # number of heads\n",
        "        self.head_dim = hid_dim // n_heads # value dim = Query dim\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim) # Query\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim) # Key\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim) # Value\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device) # scale for energy in scaled dot product\n",
        "  \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query) # (batch size, query len, hid dim)\n",
        "        K = self.fc_k(key) # (batch size, query len, hid dim)\n",
        "        V = self.fc_v(value) # (batch size, query len, hid dim)\n",
        "     \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # (batch size, n heads, query len, head dim)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # (batch size, n heads, key len, head dim)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # (batch size, n heads, value len, head dim)\n",
        "    \n",
        "        # Scaled Dot Product\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale # (batch size, n heads, query len, key len)\n",
        "        # apply mask for paddings in source sentence\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 1,  float(\"-inf\"))\n",
        "        attention = torch.softmax(energy, dim = -1) # (batch size, n heads, query len, key len)\n",
        "        x = torch.matmul(self.dropout(attention), V) # (batch size, n heads, query len, head dim)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous() # (batch size, query len, n heads, head dim)\n",
        "        x = x.view(batch_size, -1, self.hid_dim) # (batch size, query len, hid dim)\n",
        "        x = self.fc_o(x) # (batch size, query len, hid dim)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPmRem9serOi"
      },
      "source": [
        "## creating encoder layer\n",
        "\n",
        "- multihead attention\n",
        "- layer Norm\n",
        "- positionwise feed forward\n",
        "- add (residual) and layer Norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.963814Z",
          "iopub.execute_input": "2021-06-30T14:04:55.964224Z",
          "iopub.status.idle": "2021-06-30T14:04:55.975827Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.964170Z",
          "shell.execute_reply": "2021-06-30T14:04:55.975029Z"
        },
        "trusted": true,
        "id": "98Z1zx2_ZKW8"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim, eps = 1e-05)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim,  eps = 1e-05)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        #self attention\n",
        "        _src = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(self.dropout(_src))\n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU-Xk172ek-T"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "- token embedding + positional encoding\n",
        "- encdoer layer (multihead attention + add and norm + position wise feed forward + add and norm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.977386Z",
          "iopub.execute_input": "2021-06-30T14:04:55.977791Z",
          "iopub.status.idle": "2021-06-30T14:04:55.989434Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.977751Z",
          "shell.execute_reply": "2021-06-30T14:04:55.988511Z"
        },
        "trusted": true,
        "id": "yEyR_mAKZKW9"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 200):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.src_tok_emb = TokenEmbedding(input_dim, hid_dim)\n",
        "        self.positional_encoding = PositionalEncoding(hid_dim, dropout=dropout)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.positional_encoding(self.src_tok_emb(src)).to(device)\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6OwNP9RegXS"
      },
      "source": [
        "## Decoder\n",
        "- token embedding + positional encoding\n",
        "- Decoder layer of pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:55.990669Z",
          "iopub.execute_input": "2021-06-30T14:04:55.991208Z",
          "iopub.status.idle": "2021-06-30T14:04:56.002702Z",
          "shell.execute_reply.started": "2021-06-30T14:04:55.991119Z",
          "shell.execute_reply": "2021-06-30T14:04:56.001861Z"
        },
        "trusted": true,
        "id": "hFY7dasVZKW9"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, trg_vocab_size, embed_size, N, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.tgt_tok_emb = TokenEmbedding(trg_vocab_size, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, dropout=dropout)\n",
        "        self.layers = nn.ModuleList([nn.TransformerDecoderLayer(embed_size, heads, batch_first=True, layer_norm_eps = 1e-05) for i in range(N)])\n",
        "    \n",
        "    def forward(self, tgt, e_outputs, tgt_key_padding_mask, tgt_mask):\n",
        "        tgt = self.positional_encoding(self.tgt_tok_emb(tgt)).to(device)\n",
        "        for i in range(N):\n",
        "            x = self.layers[i](tgt, e_outputs, tgt_mask = tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9cT0oyhecpf"
      },
      "source": [
        "## Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:56.005200Z",
          "iopub.execute_input": "2021-06-30T14:04:56.005777Z",
          "iopub.status.idle": "2021-06-30T14:04:56.019059Z",
          "shell.execute_reply.started": "2021-06-30T14:04:56.005738Z",
          "shell.execute_reply": "2021-06-30T14:04:56.018121Z"
        },
        "trusted": true,
        "id": "-xr_BfLaZKW_"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, device):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab, d_model, N, heads,pf_dim=1024, dropout=0.1, device=device)\n",
        "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
        "        self.out = nn.Linear(d_model, trg_vocab)\n",
        "        self.softmax= nn.Softmax()\n",
        "        self.trg_pad_idx = 1\n",
        "        self.src_pad_idx =1\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):       \n",
        "        src_mask = (src == self.src_pad_idx)\n",
        "        return src_mask\n",
        "    \n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        tgt_seq_len = tgt.shape[1]\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
        "        tgt_padding_mask = (tgt == 1)\n",
        "        return tgt_mask ,tgt_padding_mask \n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask, tgt_padding_mask = self.create_mask(src, trg)\n",
        "        e_outputs = self.encoder(src, src_mask.unsqueeze(1).unsqueeze(2))\n",
        "        d_output = self.decoder(trg, e_outputs, tgt_padding_mask, trg_mask)\n",
        "        output = self.out(d_output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGxIPj0MeWaA"
      },
      "source": [
        "# Define a transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:56.020428Z",
          "iopub.execute_input": "2021-06-30T14:04:56.020852Z",
          "iopub.status.idle": "2021-06-30T14:04:59.063527Z",
          "shell.execute_reply.started": "2021-06-30T14:04:56.020815Z",
          "shell.execute_reply": "2021-06-30T14:04:59.062604Z"
        },
        "trusted": true,
        "id": "2ZoTzMeZZKXA"
      },
      "source": [
        "d_model = 256\n",
        "heads = 8\n",
        "N = 3\n",
        "src_vocab = len(english.vocab)\n",
        "trg_vocab = len(persian.vocab)\n",
        "model = Transformer(src_vocab, trg_vocab, d_model, N, heads,device)\n",
        "# initialize with Xavier initialization to prevent gradient problems (vanishing or exploding)\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:59.073579Z",
          "iopub.execute_input": "2021-06-30T14:04:59.074104Z",
          "iopub.status.idle": "2021-06-30T14:04:59.120835Z",
          "shell.execute_reply.started": "2021-06-30T14:04:59.074065Z",
          "shell.execute_reply": "2021-06-30T14:04:59.119853Z"
        },
        "trusted": true,
        "id": "bSRdfFWDZKXB",
        "outputId": "af328424-6780-45cc-de4a-7f0d1376f35a"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer1(\n",
              "  (encoder): Encoder(\n",
              "    (src_tok_emb): TokenEmbedding(\n",
              "      (embedding): Embedding(20004, 256)\n",
              "    )\n",
              "    (positional_encoding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tgt_tok_emb): TokenEmbedding(\n",
              "      (embedding): Embedding(20004, 256)\n",
              "    )\n",
              "    (positional_encoding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (out): Linear(in_features=256, out_features=20004, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ch9j-50TeMMJ"
      },
      "source": [
        "# Train and validate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:59.122231Z",
          "iopub.execute_input": "2021-06-30T14:04:59.122575Z",
          "iopub.status.idle": "2021-06-30T14:04:59.128453Z",
          "shell.execute_reply.started": "2021-06-30T14:04:59.122539Z",
          "shell.execute_reply": "2021-06-30T14:04:59.127350Z"
        },
        "trusted": true,
        "id": "pDjqZdLFZKXB"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 1) # padding index is 1 for both languages\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE,  betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:59.129882Z",
          "iopub.execute_input": "2021-06-30T14:04:59.130546Z",
          "iopub.status.idle": "2021-06-30T14:04:59.145803Z",
          "shell.execute_reply.started": "2021-06-30T14:04:59.130507Z",
          "shell.execute_reply": "2021-06-30T14:04:59.144990Z"
        },
        "trusted": true,
        "id": "ezhhPdUeZKXC"
      },
      "source": [
        "def train_model(epochs,max_iter):\n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "    iter = 0\n",
        "    total_loss = 0\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss=0\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            model.train()\n",
        "            iter+=1\n",
        "            src = batch.eng.to(device)\n",
        "            trg = batch.fa.to(device)\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "            output = model(src, trg[:,:-1])\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1) # clip gradient to prevent vanishing\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() \n",
        "            # validate every 200 iteration\n",
        "            if iter%200 ==0 :\n",
        "              val_loss = 0\n",
        "              model.eval()\n",
        "              with torch.no_grad():\n",
        "                for j, batch in enumerate(validation_iterator):\n",
        "                  src = batch.eng.to(device)\n",
        "                  trg = batch.fa.to(device)\n",
        "                  output = model(src, trg[:,:-1])\n",
        "                  output_dim = output.shape[-1]\n",
        "                  output = output.contiguous().view(-1, output_dim)\n",
        "                  trg = trg[:,1:].contiguous().view(-1)\n",
        "                  loss = criterion(output, trg)\n",
        "                  val_loss += loss.item()\n",
        "                # print train and validation loss\n",
        "                print(f' epoch:{epoch} - iteration:{iter} - train loss:{epoch_loss/(i+1)} - val loss:{val_loss/(j+1)}')\n",
        "                torch.save(model.cpu().state_dict(), 'final_model.pth') # saving model\n",
        "                model.to(device)\n",
        "                train_loss.append(epoch_loss/(i+1))\n",
        "                valid_loss.append(val_loss/(j+1))\n",
        "            # fininsh training if reach max iteration\n",
        "            if iter==max_iter :\n",
        "              print('finish training!')\n",
        "              break\n",
        "        if iter==max_iter:\n",
        "          break\n",
        "    return train_loss, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T14:04:59.146849Z",
          "iopub.execute_input": "2021-06-30T14:04:59.149233Z",
          "iopub.status.idle": "2021-06-30T19:00:48.233933Z",
          "shell.execute_reply.started": "2021-06-30T14:04:59.149188Z",
          "shell.execute_reply": "2021-06-30T19:00:48.231935Z"
        },
        "trusted": true,
        "id": "sx9Qba6hZKXE",
        "outputId": "e56caf3b-94dc-4b73-fd4e-9a844d122aec"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import  torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "train_loss, valid_loss = train_model(12, 68000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " epoch:0 - iteration:200 - train loss:7.8048627781867985 - val loss:6.751314591470166\n",
            " epoch:0 - iteration:400 - train loss:7.14746151804924 - val loss:6.21964449214044\n",
            " epoch:0 - iteration:600 - train loss:6.783007321357727 - val loss:5.891408461722258\n",
            " epoch:0 - iteration:800 - train loss:6.535782944560051 - val loss:5.683463471849388\n",
            " epoch:0 - iteration:1000 - train loss:6.351849114418029 - val loss:5.523326967809802\n",
            " epoch:0 - iteration:1200 - train loss:6.204626142581304 - val loss:5.399567226160353\n",
            " epoch:0 - iteration:1400 - train loss:6.084455585479736 - val loss:5.300377692908884\n",
            " epoch:0 - iteration:1600 - train loss:5.98210769623518 - val loss:5.220884440769659\n",
            " epoch:0 - iteration:1800 - train loss:5.894482151667277 - val loss:5.152793989448904\n",
            " epoch:0 - iteration:2000 - train loss:5.8173517284393315 - val loss:5.078912261713331\n",
            " epoch:0 - iteration:2200 - train loss:5.747775233875622 - val loss:5.028297242940029\n",
            " epoch:0 - iteration:2400 - train loss:5.687017033696175 - val loss:4.969310429831531\n",
            " epoch:0 - iteration:2600 - train loss:5.6304051056275 - val loss:4.918587975190064\n",
            " epoch:0 - iteration:2800 - train loss:5.578596731424332 - val loss:4.8742719258103415\n",
            " epoch:0 - iteration:3000 - train loss:5.531336650212606 - val loss:4.834863186328211\n",
            " epoch:0 - iteration:3200 - train loss:5.487254979014397 - val loss:4.794240189489917\n",
            " epoch:0 - iteration:3400 - train loss:5.446005561632268 - val loss:4.761131854814904\n",
            " epoch:0 - iteration:3600 - train loss:5.407557907369402 - val loss:4.737988569580506\n",
            " epoch:0 - iteration:3800 - train loss:5.371488259591555 - val loss:4.691894074021099\n",
            " epoch:0 - iteration:4000 - train loss:5.3368465198278425 - val loss:4.66421177676905\n",
            " epoch:0 - iteration:4200 - train loss:5.304730803625924 - val loss:4.636214110115978\n",
            " epoch:0 - iteration:4400 - train loss:5.27480280475183 - val loss:4.616488637211167\n",
            " epoch:0 - iteration:4600 - train loss:5.245484105089436 - val loss:4.5818764428111995\n",
            " epoch:0 - iteration:4800 - train loss:5.217319903175036 - val loss:4.556239471702932\n",
            " epoch:0 - iteration:5000 - train loss:5.190988899612427 - val loss:4.537018501869986\n",
            " epoch:0 - iteration:5200 - train loss:5.165438820398771 - val loss:4.508561531405583\n",
            " epoch:0 - iteration:5400 - train loss:5.141673628047661 - val loss:4.490234461008946\n",
            " epoch:0 - iteration:5600 - train loss:5.118748339840344 - val loss:4.467801519643481\n",
            " epoch:0 - iteration:5800 - train loss:5.096169679904806 - val loss:4.451974782765468\n",
            " epoch:0 - iteration:6000 - train loss:5.074049814303716 - val loss:4.427373332175139\n",
            " epoch:0 - iteration:6200 - train loss:5.052993917311391 - val loss:4.403534595097337\n",
            " epoch:0 - iteration:6400 - train loss:5.032420417591929 - val loss:4.386243543892263\n",
            " epoch:0 - iteration:6600 - train loss:5.013052776221073 - val loss:4.373882812428697\n",
            " epoch:0 - iteration:6800 - train loss:4.994170787194196 - val loss:4.346763808036519\n",
            " epoch:0 - iteration:7000 - train loss:4.976118124144418 - val loss:4.340418885132976\n",
            " epoch:0 - iteration:7200 - train loss:4.958385739260249 - val loss:4.319808205488687\n",
            " epoch:0 - iteration:7400 - train loss:4.941488717697762 - val loss:4.303535148584954\n",
            " epoch:0 - iteration:7600 - train loss:4.924878984125037 - val loss:4.28748268947423\n",
            " epoch:0 - iteration:7800 - train loss:4.908414738300519 - val loss:4.281126025235541\n",
            " epoch:0 - iteration:8000 - train loss:4.892509194523096 - val loss:4.264823493779263\n",
            " epoch:0 - iteration:8200 - train loss:4.877342979239255 - val loss:4.244586357669296\n",
            " epoch:0 - iteration:8400 - train loss:4.862342430012567 - val loss:4.234626148794299\n",
            " epoch:0 - iteration:8600 - train loss:4.847756072421406 - val loss:4.228650822817722\n",
            " epoch:0 - iteration:8800 - train loss:4.833264956745235 - val loss:4.200808991227195\n",
            " epoch:0 - iteration:9000 - train loss:4.81946546459198 - val loss:4.195510439560792\n",
            " epoch:0 - iteration:9200 - train loss:4.805970817907997 - val loss:4.179263532273123\n",
            " epoch:0 - iteration:9400 - train loss:4.79284504388241 - val loss:4.170489194237184\n",
            " epoch:0 - iteration:9600 - train loss:4.77980337664485 - val loss:4.152970370176797\n",
            " epoch:1 - iteration:9800 - train loss:4.1015998676845005 - val loss:4.147268933893364\n",
            " epoch:1 - iteration:10000 - train loss:4.096493218739828 - val loss:4.134646849097493\n",
            " epoch:1 - iteration:10200 - train loss:4.092266253181126 - val loss:4.12722650220461\n",
            " epoch:1 - iteration:10400 - train loss:4.086131319538239 - val loss:4.112274693105823\n",
            " epoch:1 - iteration:10600 - train loss:4.080834517845741 - val loss:4.113460733734558\n",
            " epoch:1 - iteration:10800 - train loss:4.078776870281138 - val loss:4.099126902918949\n",
            " epoch:1 - iteration:11000 - train loss:4.0770631980896 - val loss:4.088296064038143\n",
            " epoch:1 - iteration:11200 - train loss:4.072213341243684 - val loss:4.075415701955278\n",
            " epoch:1 - iteration:11400 - train loss:4.06827060766623 - val loss:4.078864643952556\n",
            " epoch:1 - iteration:11600 - train loss:4.064761019356643 - val loss:4.065606716414479\n",
            " epoch:1 - iteration:11800 - train loss:4.060829493314371 - val loss:4.048147072524668\n",
            " epoch:1 - iteration:12000 - train loss:4.057457974383706 - val loss:4.0417431091593805\n",
            " epoch:1 - iteration:12200 - train loss:4.054729550093123 - val loss:4.033291287956951\n",
            " epoch:1 - iteration:12400 - train loss:4.050904841208244 - val loss:4.0286411884789155\n",
            " epoch:1 - iteration:12600 - train loss:4.046837437092757 - val loss:4.019393415540178\n",
            " epoch:1 - iteration:12800 - train loss:4.043555220956877 - val loss:4.012581050507376\n",
            " epoch:1 - iteration:13000 - train loss:4.039584106727883 - val loss:4.0020025482801636\n",
            " epoch:1 - iteration:13200 - train loss:4.036227240862546 - val loss:3.9995737661825164\n",
            " epoch:1 - iteration:13400 - train loss:4.032643519458392 - val loss:3.992605539125817\n",
            " epoch:1 - iteration:13600 - train loss:4.028448015189021 - val loss:3.97762015422928\n",
            " epoch:1 - iteration:13800 - train loss:4.025220950063831 - val loss:3.9681111779168385\n",
            " epoch:1 - iteration:14000 - train loss:4.0223256195068355 - val loss:3.965270017240649\n",
            " epoch:1 - iteration:14200 - train loss:4.018567868634 - val loss:3.957420041627973\n",
            " epoch:1 - iteration:14400 - train loss:4.015247815416745 - val loss:3.9541079554602363\n",
            " epoch:1 - iteration:14600 - train loss:4.011552209949973 - val loss:3.9403720661858532\n",
            " epoch:1 - iteration:14800 - train loss:4.007602446136843 - val loss:3.9376694440841673\n",
            " epoch:1 - iteration:15000 - train loss:4.004375224800997 - val loss:3.9342912812099278\n",
            " epoch:1 - iteration:15200 - train loss:4.001068121136036 - val loss:3.9237875325657496\n",
            " epoch:1 - iteration:15400 - train loss:3.9977075007054714 - val loss:3.9166493627512566\n",
            " epoch:1 - iteration:15600 - train loss:3.9942926481478382 - val loss:3.9215110014532213\n",
            " epoch:1 - iteration:15800 - train loss:3.9909090991927543 - val loss:3.904938663946134\n",
            " epoch:1 - iteration:16000 - train loss:3.9870681409648823 - val loss:3.8997664636540637\n",
            " epoch:1 - iteration:16200 - train loss:3.983678212038918 - val loss:3.8890316936457268\n",
            " epoch:1 - iteration:16400 - train loss:3.9802697111319794 - val loss:3.8888266062068046\n",
            " epoch:1 - iteration:16600 - train loss:3.976504850216664 - val loss:3.8782792173813436\n",
            " epoch:1 - iteration:16800 - train loss:3.9731948248766855 - val loss:3.884407823108067\n",
            " epoch:1 - iteration:17000 - train loss:3.9703243312189134 - val loss:3.8733854761747555\n",
            " epoch:1 - iteration:17200 - train loss:3.967520541861506 - val loss:3.8664146365406356\n",
            " epoch:1 - iteration:17400 - train loss:3.964555479184608 - val loss:3.8620288984797826\n",
            " epoch:1 - iteration:17600 - train loss:3.9614396925181805 - val loss:3.856473561759307\n",
            " epoch:1 - iteration:17800 - train loss:3.9584753685697502 - val loss:3.8609866726064235\n",
            " epoch:1 - iteration:18000 - train loss:3.95555752962027 - val loss:3.8412920125176973\n",
            " epoch:1 - iteration:18200 - train loss:3.9527057892935615 - val loss:3.835285095410926\n",
            " epoch:1 - iteration:18400 - train loss:3.9498274970258405 - val loss:3.8304495820375246\n",
            " epoch:1 - iteration:18600 - train loss:3.9470299658602657 - val loss:3.822567376689376\n",
            " epoch:1 - iteration:18800 - train loss:3.944148433513797 - val loss:3.821910218434913\n",
            " epoch:1 - iteration:19000 - train loss:3.9413755121866862 - val loss:3.8240082636057773\n",
            " epoch:1 - iteration:19200 - train loss:3.9384959313016648 - val loss:3.8141715820704665\n",
            " epoch:2 - iteration:19400 - train loss:3.7343841552734376 - val loss:3.812277552346203\n",
            " epoch:2 - iteration:19600 - train loss:3.71988701411656 - val loss:3.802914647966902\n",
            " epoch:2 - iteration:19800 - train loss:3.7168045421080156 - val loss:3.800992801701911\n",
            " epoch:2 - iteration:20000 - train loss:3.7189961678187053 - val loss:3.7933070884686764\n",
            " epoch:2 - iteration:20200 - train loss:3.71623965890784 - val loss:3.8015177334580468\n",
            " epoch:2 - iteration:20400 - train loss:3.712730319396309 - val loss:3.7888627983699337\n",
            " epoch:2 - iteration:20600 - train loss:3.7120367000721117 - val loss:3.7869723473753885\n",
            " epoch:2 - iteration:20800 - train loss:3.7105121721759917 - val loss:3.778350193701058\n",
            " epoch:2 - iteration:21000 - train loss:3.7112742861339023 - val loss:3.7824447823462086\n",
            " epoch:2 - iteration:21200 - train loss:3.710736843133584 - val loss:3.782983148877866\n",
            " epoch:2 - iteration:21400 - train loss:3.7098141753396323 - val loss:3.7707374000103675\n",
            " epoch:2 - iteration:21600 - train loss:3.7079134052357774 - val loss:3.763965831738766\n",
            " epoch:2 - iteration:21800 - train loss:3.707767948169334 - val loss:3.763292265829639\n",
            " epoch:2 - iteration:22000 - train loss:3.7071556026285344 - val loss:3.76945175768059\n",
            " epoch:2 - iteration:22200 - train loss:3.704804010472055 - val loss:3.7620354786097447\n",
            " epoch:2 - iteration:22400 - train loss:3.7038018157747055 - val loss:3.754970414393416\n",
            " epoch:2 - iteration:22600 - train loss:3.7024540574515044 - val loss:3.7474511306976606\n",
            " epoch:2 - iteration:22800 - train loss:3.7018052203890304 - val loss:3.741051256099594\n",
            " epoch:2 - iteration:23000 - train loss:3.700640152422587 - val loss:3.739315257562655\n",
            " epoch:2 - iteration:23200 - train loss:3.699877223063119 - val loss:3.735607669286639\n",
            " epoch:2 - iteration:23400 - train loss:3.6986279312961075 - val loss:3.7325147744651153\n",
            " epoch:2 - iteration:23600 - train loss:3.697536594347022 - val loss:3.735966238351626\n",
            " epoch:2 - iteration:23800 - train loss:3.6963417622283266 - val loss:3.7272741081558656\n",
            " epoch:2 - iteration:24000 - train loss:3.694895437541761 - val loss:3.7280941533151073\n",
            " epoch:2 - iteration:24200 - train loss:3.694048496352302 - val loss:3.725307774320941\n",
            " epoch:2 - iteration:24400 - train loss:3.6926927905869715 - val loss:3.713289899246715\n",
            " epoch:2 - iteration:24600 - train loss:3.690492549611029 - val loss:3.7141951126472974\n",
            " epoch:2 - iteration:24800 - train loss:3.689477430292078 - val loss:3.7106626960718745\n",
            " epoch:2 - iteration:25000 - train loss:3.6880219473216846 - val loss:3.7080800591228162\n",
            " epoch:2 - iteration:25200 - train loss:3.687032596724374 - val loss:3.699407892138044\n",
            " epoch:2 - iteration:25400 - train loss:3.6855777796303353 - val loss:3.70152639451428\n",
            " epoch:2 - iteration:25600 - train loss:3.684333553952495 - val loss:3.6977638741519963\n",
            " epoch:2 - iteration:25800 - train loss:3.6828776899366886 - val loss:3.695595241929883\n",
            " epoch:2 - iteration:26000 - train loss:3.6814709342673972 - val loss:3.68850653104693\n",
            " epoch:2 - iteration:26200 - train loss:3.6809263831076864 - val loss:3.696148436983055\n",
            " epoch:2 - iteration:26400 - train loss:3.6796444430384603 - val loss:3.6849875984904923\n",
            " epoch:2 - iteration:26600 - train loss:3.6782708190736315 - val loss:3.6764733147398334\n",
            " epoch:2 - iteration:26800 - train loss:3.6771926001049824 - val loss:3.6771577986601356\n",
            " epoch:2 - iteration:27000 - train loss:3.675838787909477 - val loss:3.6754940447406232\n",
            " epoch:2 - iteration:27200 - train loss:3.6746615498920656 - val loss:3.6685747237963096\n",
            " epoch:2 - iteration:27400 - train loss:3.6731635520209562 - val loss:3.6702609686093908\n",
            " epoch:2 - iteration:27600 - train loss:3.6718512219868735 - val loss:3.6670934349577005\n",
            " epoch:2 - iteration:27800 - train loss:3.6706590050424053 - val loss:3.662224112938498\n",
            " epoch:2 - iteration:28000 - train loss:3.669088085610526 - val loss:3.659703966835949\n",
            " epoch:2 - iteration:28200 - train loss:3.6679737013278726 - val loss:3.656089933341909\n",
            " epoch:2 - iteration:28400 - train loss:3.666952769821459 - val loss:3.657782080240339\n",
            " epoch:2 - iteration:28600 - train loss:3.6659334863825914 - val loss:3.6518343361738688\n",
            " epoch:2 - iteration:28800 - train loss:3.664767986017996 - val loss:3.647378935992161\n",
            " epoch:3 - iteration:29000 - train loss:3.498708917617798 - val loss:3.645282959715228\n",
            " epoch:3 - iteration:29200 - train loss:3.5073430230067326 - val loss:3.6490198084127123\n",
            " epoch:3 - iteration:29400 - train loss:3.50273854800633 - val loss:3.6446383476257322\n",
            " epoch:3 - iteration:29600 - train loss:3.5082069811327705 - val loss:3.6470662134830083\n",
            " epoch:3 - iteration:29800 - train loss:3.5115040781691267 - val loss:3.63896429382752\n",
            " epoch:3 - iteration:30000 - train loss:3.5143478423224557 - val loss:3.6407875368528275\n",
            " epoch:3 - iteration:30200 - train loss:3.5136124430962328 - val loss:3.6376559888091045\n",
            " epoch:3 - iteration:30400 - train loss:3.512790895211892 - val loss:3.6381922570344445\n",
            " epoch:3 - iteration:30600 - train loss:3.5135206308226654 - val loss:3.6414090443994396\n",
            " epoch:3 - iteration:30800 - train loss:3.514264858171537 - val loss:3.6340211805896225\n",
            " epoch:3 - iteration:31000 - train loss:3.5130077951094685 - val loss:3.629327000858628\n",
            " epoch:3 - iteration:31200 - train loss:3.5134138051925166 - val loss:3.6291538860196266\n",
            " epoch:3 - iteration:31400 - train loss:3.5125683019656946 - val loss:3.63058814111157\n",
            " epoch:3 - iteration:31600 - train loss:3.5123619452310266 - val loss:3.6255505566285033\n",
            " epoch:3 - iteration:31800 - train loss:3.5118920634343076 - val loss:3.6235275090297807\n",
            " epoch:3 - iteration:32000 - train loss:3.511268260345459 - val loss:3.6195284039060645\n",
            " epoch:3 - iteration:32200 - train loss:3.511062532367563 - val loss:3.615828446361506\n",
            " epoch:3 - iteration:32400 - train loss:3.511588368517287 - val loss:3.6133999927021634\n",
            " epoch:3 - iteration:32600 - train loss:3.511562349652284 - val loss:3.619463844388445\n",
            " epoch:3 - iteration:32800 - train loss:3.512363519729323 - val loss:3.61231484012069\n",
            " epoch:3 - iteration:33000 - train loss:3.512618134989883 - val loss:3.6051179903689947\n",
            " epoch:3 - iteration:33200 - train loss:3.5122252467601975 - val loss:3.6046555146992763\n",
            " epoch:3 - iteration:33400 - train loss:3.5117331241375833 - val loss:3.6050155858013118\n",
            " epoch:3 - iteration:33600 - train loss:3.511896041537088 - val loss:3.5995109159255696\n",
            " epoch:3 - iteration:33800 - train loss:3.512162382590589 - val loss:3.598674697073821\n",
            " epoch:3 - iteration:34000 - train loss:3.512064889721754 - val loss:3.5951727147414307\n",
            " epoch:3 - iteration:34200 - train loss:3.5117419615373926 - val loss:3.6036119975776315\n",
            " epoch:3 - iteration:34400 - train loss:3.5116105086555307 - val loss:3.5980838973945546\n",
            " epoch:3 - iteration:34600 - train loss:3.511983784588143 - val loss:3.604123073872005\n",
            " epoch:3 - iteration:34800 - train loss:3.5117379488321294 - val loss:3.597393645750028\n",
            " epoch:3 - iteration:35000 - train loss:3.511335126215098 - val loss:3.590456200982923\n",
            " epoch:3 - iteration:35200 - train loss:3.511294019344767 - val loss:3.582451557221814\n",
            " epoch:3 - iteration:35400 - train loss:3.510892156476719 - val loss:3.586901152690994\n",
            " epoch:3 - iteration:35600 - train loss:3.510207344537331 - val loss:3.5804675897705223\n",
            " epoch:3 - iteration:35800 - train loss:3.510043568972646 - val loss:3.5769953464793267\n",
            " epoch:3 - iteration:36000 - train loss:3.510273039934928 - val loss:3.5762102479132536\n",
            " epoch:3 - iteration:36200 - train loss:3.51012341255214 - val loss:3.578488649163291\n",
            " epoch:3 - iteration:36400 - train loss:3.510047550486568 - val loss:3.57460219882359\n",
            " epoch:3 - iteration:36600 - train loss:3.5093018694448626 - val loss:3.585111232784307\n",
            " epoch:3 - iteration:36800 - train loss:3.5091730355765165 - val loss:3.569722215928764\n",
            " epoch:3 - iteration:37000 - train loss:3.5087379554161657 - val loss:3.5780102257416626\n",
            " epoch:3 - iteration:37200 - train loss:3.5086061087599747 - val loss:3.56696138983575\n",
            " epoch:3 - iteration:37400 - train loss:3.508446740544786 - val loss:3.5634170962271288\n",
            " epoch:3 - iteration:37600 - train loss:3.508024746203491 - val loss:3.5651047267646434\n",
            " epoch:3 - iteration:37800 - train loss:3.5077721796650176 - val loss:3.563737252493885\n",
            " epoch:3 - iteration:38000 - train loss:3.5073870513079917 - val loss:3.565085119844597\n",
            " epoch:3 - iteration:38200 - train loss:3.506816858567757 - val loss:3.5579328140365742\n",
            " epoch:3 - iteration:38400 - train loss:3.5065701188315246 - val loss:3.563536520984685\n",
            " epoch:4 - iteration:38600 - train loss:3.3711217069625854 - val loss:3.5552680253982545\n",
            " epoch:4 - iteration:38800 - train loss:3.373747406800588 - val loss:3.5621251168652117\n",
            " epoch:4 - iteration:39000 - train loss:3.3760746517181395 - val loss:3.551266739078771\n",
            " epoch:4 - iteration:39200 - train loss:3.373990857941764 - val loss:3.557515579963399\n",
            " epoch:4 - iteration:39400 - train loss:3.3758080614937676 - val loss:3.553040212337102\n",
            " epoch:4 - iteration:39600 - train loss:3.378165597698905 - val loss:3.5596697069774166\n",
            " epoch:4 - iteration:39800 - train loss:3.381250763122852 - val loss:3.554765895148304\n",
            " epoch:4 - iteration:40000 - train loss:3.3826736733118694 - val loss:3.5586646115668468\n",
            " epoch:4 - iteration:40200 - train loss:3.3835567708576426 - val loss:3.5526702533258456\n",
            " epoch:4 - iteration:40400 - train loss:3.385025099955107 - val loss:3.5531815831906326\n",
            " epoch:4 - iteration:40600 - train loss:3.3854080434072586 - val loss:3.552039684759122\n",
            " epoch:4 - iteration:40800 - train loss:3.385866100995437 - val loss:3.548616926023893\n",
            " epoch:4 - iteration:41000 - train loss:3.3879688529968264 - val loss:3.543581112745766\n",
            " epoch:4 - iteration:41200 - train loss:3.3890239215780187 - val loss:3.541797650863077\n",
            " epoch:4 - iteration:41400 - train loss:3.390087358540502 - val loss:3.5445993715357558\n",
            " epoch:4 - iteration:41600 - train loss:3.3911635974914796 - val loss:3.544676862698849\n",
            " epoch:4 - iteration:41800 - train loss:3.392396333145373 - val loss:3.5404637314448846\n",
            " epoch:4 - iteration:42000 - train loss:3.3933753447532653 - val loss:3.5390331163584627\n",
            " epoch:4 - iteration:42200 - train loss:3.392939784526825 - val loss:3.5382837678784522\n",
            " epoch:4 - iteration:42400 - train loss:3.393073586561741 - val loss:3.5387344578716244\n",
            " epoch:4 - iteration:42600 - train loss:3.393763017131061 - val loss:3.5345814361750523\n",
            " epoch:4 - iteration:42800 - train loss:3.3944680221136228 - val loss:3.5386139740453704\n",
            " epoch:4 - iteration:43000 - train loss:3.3951519287957086 - val loss:3.527452793968058\n",
            " epoch:4 - iteration:43200 - train loss:3.3948863940543315 - val loss:3.524818264435385\n",
            " epoch:4 - iteration:43400 - train loss:3.395761991520317 - val loss:3.5260684964812805\n",
            " epoch:4 - iteration:43600 - train loss:3.3954947458996494 - val loss:3.526790124456459\n",
            " epoch:4 - iteration:43800 - train loss:3.39585613983982 - val loss:3.537164700142691\n",
            " epoch:4 - iteration:44000 - train loss:3.3960173615108835 - val loss:3.5232048834595724\n",
            " epoch:4 - iteration:44200 - train loss:3.396344940453245 - val loss:3.5249009569114613\n",
            " epoch:4 - iteration:44400 - train loss:3.396775477498265 - val loss:3.5308448107443122\n",
            " epoch:4 - iteration:44600 - train loss:3.396901167181672 - val loss:3.520780649586259\n",
            " epoch:4 - iteration:44800 - train loss:3.3971855258184767 - val loss:3.5184866058492217\n",
            " epoch:4 - iteration:45000 - train loss:3.3973629420353815 - val loss:3.515274783161199\n",
            " epoch:4 - iteration:45200 - train loss:3.3976046059380716 - val loss:3.5161930817309943\n",
            " epoch:4 - iteration:45400 - train loss:3.3980855531277863 - val loss:3.5161495320150786\n",
            " epoch:4 - iteration:45600 - train loss:3.398517414247486 - val loss:3.5164101424618304\n",
            " epoch:4 - iteration:45800 - train loss:3.3983888392252464 - val loss:3.514284210338771\n",
            " epoch:4 - iteration:46000 - train loss:3.398705979569753 - val loss:3.5134161307432943\n",
            " epoch:4 - iteration:46200 - train loss:3.399142018262442 - val loss:3.508665108235083\n",
            " epoch:4 - iteration:46400 - train loss:3.3988375719589525 - val loss:3.507287176078725\n",
            " epoch:4 - iteration:46600 - train loss:3.398694729687255 - val loss:3.5095924624772827\n",
            " epoch:4 - iteration:46800 - train loss:3.3987080533820464 - val loss:3.5035858174350776\n",
            " epoch:4 - iteration:47000 - train loss:3.398649820832645 - val loss:3.5032848741406593\n",
            " epoch:4 - iteration:47200 - train loss:3.3983397641127135 - val loss:3.5035009319537154\n",
            " epoch:4 - iteration:47400 - train loss:3.3986441284351137 - val loss:3.500979613143707\n",
            " epoch:4 - iteration:47600 - train loss:3.3987568935457166 - val loss:3.49932412232194\n",
            " epoch:4 - iteration:47800 - train loss:3.3991136040226104 - val loss:3.501514369305049\n",
            " epoch:4 - iteration:48000 - train loss:3.3993670951190746 - val loss:3.5069568195075633\n",
            " epoch:5 - iteration:48200 - train loss:3.298314956029256 - val loss:3.4969944777889785\n",
            " epoch:5 - iteration:48400 - train loss:3.283799170580777 - val loss:3.501812339497504\n",
            " epoch:5 - iteration:48600 - train loss:3.277524001472875 - val loss:3.5096061809040675\n",
            " epoch:5 - iteration:48800 - train loss:3.282695795341774 - val loss:3.5022617110582157\n",
            " epoch:5 - iteration:49000 - train loss:3.2879746864863804 - val loss:3.4989767194908357\n",
            " epoch:5 - iteration:49200 - train loss:3.2900340339749357 - val loss:3.501221125148167\n",
            " epoch:5 - iteration:49400 - train loss:3.289150581359863 - val loss:3.504369558352176\n",
            " epoch:5 - iteration:49600 - train loss:3.292200374926551 - val loss:3.500860200195669\n",
            " epoch:5 - iteration:49800 - train loss:3.293480973884241 - val loss:3.4983639244721316\n",
            " epoch:5 - iteration:50000 - train loss:3.29376017443339 - val loss:3.500973109218562\n",
            " epoch:5 - iteration:50200 - train loss:3.2946803842107935 - val loss:3.4965172415581818\n",
            " epoch:5 - iteration:50400 - train loss:3.296773903605702 - val loss:3.495747217062478\n",
            " epoch:5 - iteration:50600 - train loss:3.297868720353252 - val loss:3.4947771373196184\n",
            " epoch:5 - iteration:50800 - train loss:3.29883418421879 - val loss:3.492626868452981\n",
            " epoch:5 - iteration:51000 - train loss:3.300141241239465 - val loss:3.4888802746746026\n",
            " epoch:5 - iteration:51200 - train loss:3.3010527770499873 - val loss:3.4884097458046175\n",
            " epoch:5 - iteration:51400 - train loss:3.301042882322355 - val loss:3.4937523282576946\n",
            " epoch:5 - iteration:51600 - train loss:3.302826286494303 - val loss:3.485151894070278\n",
            " epoch:5 - iteration:51800 - train loss:3.304238346125804 - val loss:3.489927072391332\n",
            " epoch:5 - iteration:52000 - train loss:3.3047932139981175 - val loss:3.4856639463210772\n",
            " epoch:5 - iteration:52200 - train loss:3.305275477251392 - val loss:3.485421108976703\n",
            " epoch:5 - iteration:52400 - train loss:3.3066530795961793 - val loss:3.4850376924621727\n",
            " epoch:5 - iteration:52600 - train loss:3.306847368378879 - val loss:3.4855607527438726\n",
            " epoch:5 - iteration:52800 - train loss:3.3075766220704756 - val loss:3.4872667145506244\n",
            " epoch:5 - iteration:53000 - train loss:3.308386963673127 - val loss:3.488512700963243\n",
            " epoch:5 - iteration:53200 - train loss:3.309028035713534 - val loss:3.478143828605937\n",
            " epoch:5 - iteration:53400 - train loss:3.3100170721713966 - val loss:3.4790581832422274\n",
            " epoch:5 - iteration:53600 - train loss:3.310792849118307 - val loss:3.4779247520125915\n",
            " epoch:5 - iteration:53800 - train loss:3.311990389886932 - val loss:3.474011364161411\n",
            " epoch:5 - iteration:54000 - train loss:3.3124568981819964 - val loss:3.479683134043328\n",
            " epoch:5 - iteration:54200 - train loss:3.3126959127261313 - val loss:3.4754482908783673\n",
            " epoch:5 - iteration:54400 - train loss:3.3129917368945847 - val loss:3.474758995804831\n",
            " epoch:5 - iteration:54600 - train loss:3.3138028707835665 - val loss:3.4750037518617147\n",
            " epoch:5 - iteration:54800 - train loss:3.3145537604285535 - val loss:3.4779135153672405\n",
            " epoch:5 - iteration:55000 - train loss:3.31526917998574 - val loss:3.470657529117905\n",
            " epoch:5 - iteration:55200 - train loss:3.3155313873291017 - val loss:3.476293847048394\n",
            " epoch:5 - iteration:55400 - train loss:3.316053072218223 - val loss:3.4701181676900275\n",
            " epoch:5 - iteration:55600 - train loss:3.3167908390389638 - val loss:3.4676753503139888\n",
            " epoch:5 - iteration:55800 - train loss:3.3173706986306155 - val loss:3.4673751873390697\n",
            " epoch:5 - iteration:56000 - train loss:3.3176226246546183 - val loss:3.463081186062822\n",
            " epoch:5 - iteration:56200 - train loss:3.3178537020963783 - val loss:3.4595070720833037\n",
            " epoch:5 - iteration:56400 - train loss:3.3186045248486846 - val loss:3.4608378236538897\n",
            " epoch:5 - iteration:56600 - train loss:3.318805989825268 - val loss:3.4575505290076\n",
            " epoch:5 - iteration:56800 - train loss:3.3192396895548795 - val loss:3.45674691333949\n",
            " epoch:5 - iteration:57000 - train loss:3.3192657828263834 - val loss:3.456283060858183\n",
            " epoch:5 - iteration:57200 - train loss:3.3195316869562324 - val loss:3.4583416031899854\n",
            " epoch:5 - iteration:57400 - train loss:3.319936070326525 - val loss:3.456517783058024\n",
            " epoch:5 - iteration:57600 - train loss:3.320195840115912 - val loss:3.454689110996567\n",
            " epoch:6 - iteration:57800 - train loss:3.2281405687332154 - val loss:3.451272677929602\n",
            " epoch:6 - iteration:58000 - train loss:3.2294825162887575 - val loss:3.459325795530159\n",
            " epoch:6 - iteration:58200 - train loss:3.2252521737416586 - val loss:3.4603403615060255\n",
            " epoch:6 - iteration:58400 - train loss:3.223782016313993 - val loss:3.4601197347462733\n",
            " epoch:6 - iteration:58600 - train loss:3.2231119341008805 - val loss:3.4687991030862397\n",
            " epoch:6 - iteration:58800 - train loss:3.2266362605776107 - val loss:3.4569436296124323\n",
            " epoch:6 - iteration:59000 - train loss:3.2283589241027832 - val loss:3.461494417502501\n",
            " epoch:6 - iteration:59200 - train loss:3.226179222238475 - val loss:3.4569332735560763\n",
            " epoch:6 - iteration:59400 - train loss:3.22437113718553 - val loss:3.4596388397929823\n",
            " epoch:6 - iteration:59600 - train loss:3.2253632760692286 - val loss:3.4537240458426073\n",
            " epoch:6 - iteration:59800 - train loss:3.2262855643760866 - val loss:3.457138858108877\n",
            " epoch:6 - iteration:60000 - train loss:3.2292444609536064 - val loss:3.4570088052303993\n",
            " epoch:6 - iteration:60200 - train loss:3.2309207526031805 - val loss:3.457445825817429\n",
            " epoch:6 - iteration:60400 - train loss:3.2326440624920827 - val loss:3.4551540517361365\n",
            " epoch:6 - iteration:60600 - train loss:3.232598807769909 - val loss:3.453424148916084\n",
            " epoch:6 - iteration:60800 - train loss:3.2333752663409125 - val loss:3.460764882052056\n",
            " epoch:6 - iteration:61000 - train loss:3.2351334839600785 - val loss:3.45336767267958\n",
            " epoch:6 - iteration:61200 - train loss:3.237065310754638 - val loss:3.450974955959855\n",
            " epoch:6 - iteration:61400 - train loss:3.2376958047527156 - val loss:3.452166286807194\n",
            " epoch:6 - iteration:61600 - train loss:3.23817638973137 - val loss:3.45570070988664\n",
            " epoch:6 - iteration:61800 - train loss:3.2386519526846613 - val loss:3.455090291923452\n",
            " epoch:6 - iteration:62000 - train loss:3.2398790742649752 - val loss:3.4504855987067535\n",
            " epoch:6 - iteration:62200 - train loss:3.240379115115391 - val loss:3.445160743232085\n",
            " epoch:6 - iteration:62400 - train loss:3.241346916024403 - val loss:3.449576412405923\n",
            " epoch:6 - iteration:62600 - train loss:3.2422073846993986 - val loss:3.440339389025608\n",
            " epoch:6 - iteration:62800 - train loss:3.2433781697962543 - val loss:3.444037875059609\n",
            " epoch:6 - iteration:63000 - train loss:3.244154272806077 - val loss:3.44473284093019\n",
            " epoch:6 - iteration:63200 - train loss:3.24469070539562 - val loss:3.4444084047157073\n",
            " epoch:6 - iteration:63400 - train loss:3.245596158694377 - val loss:3.4418908395499828\n",
            " epoch:6 - iteration:63600 - train loss:3.246445922036456 - val loss:3.4387036214365025\n",
            " epoch:6 - iteration:63800 - train loss:3.2470125461609896 - val loss:3.4398240098329347\n",
            " epoch:6 - iteration:64000 - train loss:3.247669793815613 - val loss:3.4379217221358114\n",
            " epoch:6 - iteration:64200 - train loss:3.2475385460742685 - val loss:3.437365053970123\n",
            " epoch:6 - iteration:64400 - train loss:3.2480783024407867 - val loss:3.4346986113307634\n",
            " epoch:6 - iteration:64600 - train loss:3.248805209424374 - val loss:3.4378687256964566\n",
            " epoch:6 - iteration:64800 - train loss:3.2495662947918507 - val loss:3.439602908909878\n",
            " epoch:6 - iteration:65000 - train loss:3.2502075512984705 - val loss:3.4390483185509657\n",
            " epoch:6 - iteration:65200 - train loss:3.2508170613026457 - val loss:3.4377631338957313\n",
            " epoch:6 - iteration:65400 - train loss:3.251528598841499 - val loss:3.426935490269527\n",
            " epoch:6 - iteration:65600 - train loss:3.252319374327447 - val loss:3.429358001512902\n",
            " epoch:6 - iteration:65800 - train loss:3.2528432867986075 - val loss:3.429704742119691\n",
            " epoch:6 - iteration:66000 - train loss:3.2532910244103634 - val loss:3.424541228731102\n",
            " epoch:6 - iteration:66200 - train loss:3.253886572454103 - val loss:3.4277571756149006\n",
            " epoch:6 - iteration:66400 - train loss:3.254157929916602 - val loss:3.430202323254024\n",
            " epoch:6 - iteration:66600 - train loss:3.2543150901255635 - val loss:3.4245012434843543\n",
            " epoch:6 - iteration:66800 - train loss:3.25510467002405 - val loss:3.428466644019724\n",
            " epoch:6 - iteration:67000 - train loss:3.255743978371491 - val loss:3.427644906534213\n",
            " epoch:6 - iteration:67200 - train loss:3.2565207299227437 - val loss:3.4228469235874783\n",
            " epoch:7 - iteration:67400 - train loss:3.1571295356750486 - val loss:3.422329762494453\n",
            " epoch:7 - iteration:67600 - train loss:3.1452703179253474 - val loss:3.426532861228301\n",
            " epoch:7 - iteration:67800 - train loss:3.146325338588041 - val loss:3.4284775687155324\n",
            " epoch:7 - iteration:68000 - train loss:3.149474352645874 - val loss:3.426794737521733\n",
            "finish training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.236297Z",
          "iopub.execute_input": "2021-06-30T19:00:48.236851Z",
          "iopub.status.idle": "2021-06-30T19:00:48.493178Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.236805Z",
          "shell.execute_reply": "2021-06-30T19:00:48.492373Z"
        },
        "trusted": true,
        "id": "sjoBXWOWZKXE",
        "outputId": "41357924-5283-42bf-e0a1-f7704ae4b283"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "plt.title('Loss per iteration')\n",
        "plt.xlabel('iteration')\n",
        "#plt.xticks([i for i in range(200, (len(train_loss)+1)*200,200)])\n",
        "plt.ylabel('loss')\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(valid_loss, label='validation')\n",
        "plt.xticks(rotation=45)\n",
        "locs, labels = plt.xticks()\n",
        "labels = [(int(item))*200 for item in locs]\n",
        "plt.xticks(locs, labels)\n",
        "plt.xlim(xmin=-0.9, xmax = (len(train_loss)+1))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H76zKwfMeAfw"
      },
      "source": [
        "# Test and evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.494506Z",
          "iopub.execute_input": "2021-06-30T19:00:48.494855Z",
          "iopub.status.idle": "2021-06-30T19:00:48.506476Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.494818Z",
          "shell.execute_reply": "2021-06-30T19:00:48.505454Z"
        },
        "trusted": true,
        "id": "05C_I9KfZKXF"
      },
      "source": [
        "test_text_fa0 = open('./Test/test.fa0', encoding='utf8').read().splitlines()\n",
        "test_text_fa1 = open('./Test/test.fa1', encoding='utf8').read().splitlines()\n",
        "test_text_fa2 = open('./Test/test.fa2', encoding='utf8').read().splitlines()\n",
        "test_text_fa3 = open('./Test/test.fa3', encoding='utf8').read().splitlines()\n",
        "test_text_eng =  open('./Test/test.en', encoding='utf8').read().splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VebVltSYd_An"
      },
      "source": [
        "## Translation Function\n",
        "- based on greedy search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.507726Z",
          "iopub.execute_input": "2021-06-30T19:00:48.508183Z",
          "iopub.status.idle": "2021-06-30T19:00:48.517913Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.508136Z",
          "shell.execute_reply": "2021-06-30T19:00:48.517034Z"
        },
        "trusted": true,
        "id": "t-AvA6WPZKXF"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):  \n",
        "    model.eval()\n",
        "    tokens = nltk.word_tokenize(sentence.lower()) # tokenize source sentence\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token] # add <SOS> and <EOS>\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens] # map tokens to index in source vocab\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor) # make mask for if there is padding\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask) # output of encoder\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]] # strat translation with <SOS> token\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask, tgt_padding_mask = model.create_mask(src_tensor, trg_tensor) \n",
        "        with torch.no_grad():\n",
        "          output = model.decoder(trg_tensor, enc_src, tgt_padding_mask, trg_mask)\n",
        "          output = model.out(output)   \n",
        "        pred_token = output.argmax(2)[:,-1].item() # select maximum probable token due to gready search\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkrnvEqrd5Va"
      },
      "source": [
        "## test translate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.519405Z",
          "iopub.execute_input": "2021-06-30T19:00:48.519892Z",
          "iopub.status.idle": "2021-06-30T19:00:48.534318Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.519856Z",
          "shell.execute_reply": "2021-06-30T19:00:48.533268Z"
        },
        "trusted": true,
        "id": "uwgYHH2rZKXF",
        "outputId": "ea27ff52-1b4b-469e-fdbe-0df33da3a092"
      },
      "source": [
        "src = test_text_eng[43] # 43, 88\n",
        "print(src)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I did not understand , what you said about the hotel .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.537764Z",
          "iopub.execute_input": "2021-06-30T19:00:48.538067Z",
          "iopub.status.idle": "2021-06-30T19:00:48.653801Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.538041Z",
          "shell.execute_reply": "2021-06-30T19:00:48.652896Z"
        },
        "trusted": true,
        "id": "B2hqu_7EZKXG",
        "outputId": "e2d1adf2-6e3a-4bb2-eeeb-c67ecf743dc3"
      },
      "source": [
        "trg  = translate_sentence(src, english, persian, model, device, max_len = 50)\n",
        "print(\" \".join(trg[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "من چیزی را در مورد هتل گفتم , چیزی در مورد آن ندارم .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_moku07dzfB"
      },
      "source": [
        "## calculate BLUE and NIST score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.655379Z",
          "iopub.execute_input": "2021-06-30T19:00:48.655742Z",
          "iopub.status.idle": "2021-06-30T19:00:48.660539Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.655703Z",
          "shell.execute_reply": "2021-06-30T19:00:48.659376Z"
        },
        "trusted": true,
        "id": "hBcqE0aoZKXG"
      },
      "source": [
        "from nltk.translate import nist_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.662146Z",
          "iopub.execute_input": "2021-06-30T19:00:48.662632Z",
          "iopub.status.idle": "2021-06-30T19:00:48.857451Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.662578Z",
          "shell.execute_reply": "2021-06-30T19:00:48.856562Z"
        },
        "trusted": true,
        "id": "uVLO6bqSZKXH"
      },
      "source": [
        "test_sentences =  [sentence for sentence in test_text_eng]\n",
        "refrences = [[tokenizer_fa(test_text_fa0[i]), tokenizer_fa(test_text_fa1[i]), tokenizer_fa(test_text_fa2[i]), tokenizer_fa(test_text_fa3[i])] for i in range(len(test_text_fa3))]\n",
        "test_results=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:00:48.860080Z",
          "iopub.execute_input": "2021-06-30T19:00:48.860471Z",
          "iopub.status.idle": "2021-06-30T19:01:00.383069Z",
          "shell.execute_reply.started": "2021-06-30T19:00:48.860440Z",
          "shell.execute_reply": "2021-06-30T19:01:00.382123Z"
        },
        "trusted": true,
        "id": "SmX8bRRjZKXH",
        "outputId": "d27ff3d8-bb58-48bf-a146-19307cd501cf"
      },
      "source": [
        "blue_scores = []\n",
        "Nist_score = []\n",
        "for i in range(len(test_sentences)):\n",
        "  src = test_sentences[i]\n",
        "  trg  = translate_sentence(src, english, persian, model, device, max_len = 50)\n",
        "  test_results.append(trg[:-1])\n",
        "  blue_scores.append(nltk.translate.bleu_score.corpus_bleu([refrences[i]], [trg[:-1]]))\n",
        "  try:\n",
        "    Nist_score.append(nist_score.corpus_nist([refrences[i]], [trg[:-1]]))\n",
        "  except ZeroDivisionError:\n",
        "    Nist_score.append(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:01:00.384400Z",
          "iopub.execute_input": "2021-06-30T19:01:00.384787Z",
          "iopub.status.idle": "2021-06-30T19:01:00.390009Z",
          "shell.execute_reply.started": "2021-06-30T19:01:00.384746Z",
          "shell.execute_reply": "2021-06-30T19:01:00.389130Z"
        },
        "trusted": true,
        "id": "yz4aAl6bZKXI",
        "outputId": "3e9dca76-eed0-4fc7-f078-878de5d28139"
      },
      "source": [
        "print(f'mean BLUE: {np.mean(blue_scores)}')\n",
        "print(f'mean NIST: {np.mean(Nist_score)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean BLUE: 0.06977151970607721\n",
            "mean NIST: 1.6115396089719476\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOKEer1cdvP4"
      },
      "source": [
        "## Some of translations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T19:01:00.391156Z",
          "iopub.execute_input": "2021-06-30T19:01:00.391660Z",
          "iopub.status.idle": "2021-06-30T19:01:00.408635Z",
          "shell.execute_reply.started": "2021-06-30T19:01:00.391622Z",
          "shell.execute_reply": "2021-06-30T19:01:00.407728Z"
        },
        "trusted": true,
        "id": "p7mfA_MsZKXI",
        "outputId": "7ea94646-033c-4f32-fc6f-60297dce59c1"
      },
      "source": [
        "for i in range(50):\n",
        "    sentence = test_sentences[i]\n",
        "    translation = \" \".join(test_results[i])\n",
        "    print(f'{i}: original sentence: {sentence} \\ntranslation: {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: original sentence: hello , do we drive together to Hanover on the twenty-eighth of March ? \n",
            "translation: سلام , سلام , <unk> با هم <unk> <unk> ?\n",
            "1: original sentence: it is more comfortable by train . \n",
            "translation: با این روش راحت تر است .\n",
            "2: original sentence: do you go by car and I go by train ? \n",
            "translation: من با ماشین <unk> و شما را به قطار می برم ?\n",
            "3: original sentence: I would like to go by train . and what would you like ? \n",
            "translation: من دوست دارم شما چه کاری می کنم ? و آموزش شما را دوست دارم .\n",
            "4: original sentence: if we take the $I-$C-$E train at six past seven , we will arrive at twenty-five past eight . \n",
            "translation: ما پنج داریم که <unk> <unk> <unk> دلار در شش ماه می کنیم , در حالی که ما در پنج تا 7 دلار به بعد از ظهر به توافق رسیده ایم .\n",
            "5: original sentence: which cafe ? \n",
            "translation: چه کسی را در نظر بگیرید ?\n",
            "6: original sentence: the cafe at platform fourteen . \n",
            "translation: 14 ساعت در کافه , برگذار می شود .\n",
            "7: original sentence: in any case a cheap hotel . \n",
            "translation: هر هتل در یک هتل ارزان است .\n",
            "8: original sentence: what did you say , please ? \n",
            "translation: چه طور ? شما گفتید , لطفا ?\n",
            "9: original sentence: and how much is a single room ? \n",
            "translation: اتاق بازرگانی و اتاق بازرگانی است ?\n",
            "10: original sentence: we can take a taxi from the station to the hotel . \n",
            "translation: ما می توانیم از هتل را به یک هتل <unk> .\n",
            "11: original sentence: at which hotel do you want to reserve a room now and how much is a single room ? \n",
            "translation: آیا شما می توانید یک اتاق هتل را در اتاق هتل دارید ? و یک اتاق دیگری که هنوز در حال حاضر می توانید ببینید .\n",
            "12: original sentence: okay , should we drive back on Friday evening ? \n",
            "translation: باشه , ما باید جمعه , بعد از ظهر به <unk> ?\n",
            "13: original sentence: I think we rather drive back at thirty-three past nine then we will arrive at Hamburg at fifty-two past ten . \n",
            "translation: من فکر میکنم ما در ساعت 9 به نظر می رسد که در آخر سپتامبر به مرحله ی بعدی به <unk> , ما در قطار سریع السیر <unk> .\n",
            "14: original sentence: fine and don't forget your swimming stuff , maybe we can go swimming together . \n",
            "translation: می توانید شنا کنید , و ما را فراموش کنید , و <unk> را در حالی که می توانید شنا کنید .\n",
            "15: original sentence: yes . when and where do we want to meet ? \n",
            "translation: بله , چه زمانی را می بینم ? و کجا قرار ملاقات کنیم ?\n",
            "16: original sentence: I prefer the plane . \n",
            "translation: من هواپیما را ترجیح میدهم .\n",
            "17: original sentence: a good idea . then we will meet at the airport tomorrow . \n",
            "translation: پس فردا ما در فرودگاه خوبی برای ملاقات خواهیم کرد .\n",
            "18: original sentence: no idea . we will see . it does not matter . \n",
            "translation: نه . ما این موضوع را نه .\n",
            "19: original sentence: good . let us meet at nine o'clock . hopefully the plane won't be hijacked tomorrow . \n",
            "translation: نه . فردا , اجازه دهید که فردا پرواز ما را به هواپیما به ما اجازه دهیم .\n",
            "20: original sentence: I have already booked two rooms at the Gr\"unschnabel . \n",
            "translation: من قبلا دو اتاق را در اتاق بازرگانی <unk> قرار داده ام . ''\n",
            "21: original sentence: what did you say ? \n",
            "translation: چه چیزی را گفتید ?\n",
            "22: original sentence: yes . we have two rooms at the Gr\"unschnabel . I will reserve a taxi right now . \n",
            "translation: بله , ما اکنون در یک اتاق کوچک اجاره ای داریم . ''\n",
            "23: original sentence: what is planned for the evening ? \n",
            "translation: برنامه بعدازظهر چیست ?\n",
            "24: original sentence: a good idea . I have heard , Phantom of the opera is supposed to be played . \n",
            "translation: خوب , من فکر کردم که ایده خوبی است که در مورد آن قرار گرفته باشد .\n",
            "25: original sentence: fine . I think we have arranged everything . then we will meet tomorrow . \n",
            "translation: خوب است . فکر میکنم ما فردا همدیگر را ملاقات کنیم . پس فردا .\n",
            "26: original sentence: hello . we have to talk about our trip to Hanover . \n",
            "translation: سلام . ما درباره سفر به برلین با ما صحبت میکنیم .\n",
            "27: original sentence: right . we will be at the Expo two thousand in Hanover on the fourth and fifth of September . \n",
            "translation: ما در پنجم سپتامبر در ساعت دو و چهارم سپتامبر در برلین خواهم بود .\n",
            "28: original sentence: I have already booked a flight . \n",
            "translation: من قبلا یک پرواز دارم .\n",
            "29: original sentence: we will set off at a quarter past eight and arrive at Hanover at twelve o'clock . \n",
            "translation: ما در هشت و نیم پیش از ساعت دوازده و نیم به توافق برسیم .\n",
            "30: original sentence: we will have to meet at the airport at seven o'clock . \n",
            "translation: ما باید در هفت فرودگاه ملاقات کنیم .\n",
            "31: original sentence: we arrive at Hanover at twelve o'clock midday . \n",
            "translation: ساعت دوازده ظهر به <unk> در <unk> .\n",
            "32: original sentence: fine . which hotel do you have in mind ? \n",
            "translation: خوب است ? شما هتل دارید .\n",
            "33: original sentence: the Intercontinental is my favourite hotel in Hanover . \n",
            "translation: هتل من در هتل <unk> است .\n",
            "34: original sentence: thank you . how do we go back again to Hamburg ? \n",
            "translation: ما دوباره به خاطر اینکه به عقب نشینی کنیم ? آیا ما دوباره به عقب نشینی کنیم ?\n",
            "35: original sentence: we will go back by train on the fifth of September . \n",
            "translation: ما به قطار تا سپتامبر پنجم سپتامبر ادامه می دهیم .\n",
            "36: original sentence: the best thing is we meet at the train station at eight o'clock . \n",
            "translation: ما هشت ساعت در بهترین قطار در <unk> ملاقات می کنیم .\n",
            "37: original sentence: exactly . the train leaves Hanover at six minutes after eight . \n",
            "translation: هشت دقیقه بعد از ظهر به هشت دقیقه وقت تابستانی بریتانیا درس می دهد .\n",
            "38: original sentence: we leave Hanover at eight o'clock and arrive at Hamburg at half past nine . \n",
            "translation: هشت و نیم در دقیقه و نیم در ایستگاه قطار در وین هشت و نیم گذشته به ثمر رسید .\n",
            "39: original sentence: goodbye . \n",
            "translation: خداحافظ .\n",
            "40: original sentence: I would prefer to fly . \n",
            "translation: من ترجیح میدهم .\n",
            "41: original sentence: yes , there is a flight at a quarter past nine . \n",
            "translation: بله , یک پرواز در ساعت نه , یک چهارم است .\n",
            "42: original sentence: the plane arrives in Hanover at twenty-five past twelve . \n",
            "translation: دوازده در ساعت گذشته , بیست و پنجم به توافق رسیدند .\n",
            "43: original sentence: I did not understand , what you said about the hotel . \n",
            "translation: من چیزی را در مورد هتل گفتم , چیزی در مورد آن ندارم .\n",
            "44: original sentence: yes , would you please book two rooms . \n",
            "translation: بله , لطفا دو اتاق را <unk> .\n",
            "45: original sentence: the single room costs a hundred Deutsch-marks . did I understand you right ? \n",
            "translation: آیا شما یک اتاق بازرگانی را با قیمت بسیار عالی ? من می توانید 100 دلار را توضیح دهید .\n",
            "46: original sentence: where is this hotel ? \n",
            "translation: هتل کجا است ?\n",
            "47: original sentence: when do we meet ? \n",
            "translation: چه زمانی همدیگر را ملاقات میکنیم ?\n",
            "48: original sentence: yes , would you please book this hotel . \n",
            "translation: بله , هتل را با شما هتل <unk> .\n",
            "49: original sentence: please repeat this once again . \n",
            "translation: دوباره تکرار کنید .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJVoTtrwZKXJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}