{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "DL_HW4_part1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCRzcTPbd788"
      },
      "source": [
        "# import data and libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLX72rS7HVqs"
      },
      "source": [
        "- download data from google drive to kaggle \n",
        "- unzip data\n",
        "- upgrade torch, torchtext, torchvision and nltk libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "TYq3HcM2aENZ"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3XRJCnf5aENg"
      },
      "source": [
        "! pip install -q gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IdxOmRUlaENh"
      },
      "source": [
        "! gdown 'https://drive.google.com/u/0/uc?id=1AoiQCXqFbqETGILCpgFgozYJvmyGfq_9&export=download'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Nrpb03FLaENj"
      },
      "source": [
        "! gdown 'https://drive.google.com/u/0/uc?id=1zmdERncg0zcrqpdCzOzth0exYevXxEp2&export=download'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jqRjr-VhaENk"
      },
      "source": [
        "! unzip './AFEC-merged-all.zip'\n",
        "!unzip './Test.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SkER3_JSaENm"
      },
      "source": [
        "! pip install --upgrade nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kZh5dviUaENo"
      },
      "source": [
        "pip install --upgrade torchtext"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NZk---_5aENp"
      },
      "source": [
        "pip install --upgrade torch torchvision"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9V5VvKze7sl"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CYwhCBoH1qw"
      },
      "source": [
        "- read data line by line\n",
        "- create a pandas data frame\n",
        "- split data to train (90%) and validation (10%)\n",
        "- save train and validation data frames\n",
        "\n",
        "> with help of this [tutorail](https://youtu.be/DaHAzCaXWYQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:34:52.596411Z",
          "iopub.execute_input": "2021-06-30T08:34:52.596982Z",
          "iopub.status.idle": "2021-06-30T08:34:53.090617Z",
          "shell.execute_reply.started": "2021-06-30T08:34:52.596937Z",
          "shell.execute_reply": "2021-06-30T08:34:53.089714Z"
        },
        "trusted": true,
        "id": "kmZaqsAoaENq"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:35:18.397567Z",
          "iopub.execute_input": "2021-06-30T08:35:18.397933Z",
          "iopub.status.idle": "2021-06-30T08:35:20.204403Z",
          "shell.execute_reply.started": "2021-06-30T08:35:18.397901Z",
          "shell.execute_reply": "2021-06-30T08:35:20.203307Z"
        },
        "trusted": true,
        "id": "_oKurwkWaENs"
      },
      "source": [
        "text_fa = open('./AFEC-merged.fa', encoding='utf8').read().splitlines()\n",
        "text_eng =  open('./AFEC-merged.en', encoding='utf8').read().splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:35:25.254020Z",
          "iopub.execute_input": "2021-06-30T08:35:25.254379Z",
          "iopub.status.idle": "2021-06-30T08:35:25.258043Z",
          "shell.execute_reply.started": "2021-06-30T08:35:25.254346Z",
          "shell.execute_reply": "2021-06-30T08:35:25.257240Z"
        },
        "trusted": true,
        "id": "pW0wrNkfaENt"
      },
      "source": [
        "persian_english_text = {'English':text_eng, 'Persian':text_fa}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:35:38.781648Z",
          "iopub.execute_input": "2021-06-30T08:35:38.782094Z",
          "iopub.status.idle": "2021-06-30T08:35:39.229315Z",
          "shell.execute_reply.started": "2021-06-30T08:35:38.782061Z",
          "shell.execute_reply": "2021-06-30T08:35:39.228536Z"
        },
        "trusted": true,
        "id": "XFdiK9_AaENu",
        "outputId": "fa45bf9a-1127-4569-e644-614c118f3652"
      },
      "source": [
        "df =pd.DataFrame(persian_english_text, columns=['English', 'Persian'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  English  \\\n",
              "0       North Waziristan operation kills 50 more milit...   \n",
              "1       PESHAWAR - The on - goingmilitary operation in...   \n",
              "2       The Pakistani Air Force conducted airstrikes a...   \n",
              "3       A day earlier , at least 27 militants were rep...   \n",
              "4       Meanwhile , a roadside blast on Bangidar road ...   \n",
              "...                                                   ...   \n",
              "684412  that is an excellent idea . when is your birth...   \n",
              "684413  fine , then we will go back by train to Hambur...   \n",
              "684414  well , I think , eight o ' clock in the evenin...   \n",
              "684415  there is a train at thirty-three past six o ' ...   \n",
              "684416                                         goodbye .    \n",
              "\n",
              "                                                  Persian  \n",
              "0          مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی  \n",
              "1       پیشاور - به گزارش جیو نیوز , عملیات ادامه دار ...  \n",
              "2       به گزارش رسانه‌ها , نیروی هوایی پاکستان حملات ...  \n",
              "3       یک روز پیشتر گزارش شده بود که دست کم 27 ستیزه ...  \n",
              "4       در ضمن , مسئولان گفتند که یک انفجار کنارجاده ا...  \n",
              "...                                                   ...  \n",
              "684412           این یک فکر عالی است . تولد شما کی است ?   \n",
              "684413  خوب , بنابراین ما با قطار در سه و سی و سه دقیق...  \n",
              "684414  خوب , من فکر میکنم , ساعت هشت بعداز ظهر کافی ا...  \n",
              "684415  یک قطار برای ساعت شش و سی و سه دقیقه وجود دارد...  \n",
              "684416                                         خداحافظ .   \n",
              "\n",
              "[684417 rows x 2 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Persian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North Waziristan operation kills 50 more milit...</td>\n",
              "      <td>مرگ 50 ستیزه جوی دیگر در عملیات وزیرستان شمالی</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PESHAWAR - The on - goingmilitary operation in...</td>\n",
              "      <td>پیشاور - به گزارش جیو نیوز , عملیات ادامه دار ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Pakistani Air Force conducted airstrikes a...</td>\n",
              "      <td>به گزارش رسانه‌ها , نیروی هوایی پاکستان حملات ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A day earlier , at least 27 militants were rep...</td>\n",
              "      <td>یک روز پیشتر گزارش شده بود که دست کم 27 ستیزه ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Meanwhile , a roadside blast on Bangidar road ...</td>\n",
              "      <td>در ضمن , مسئولان گفتند که یک انفجار کنارجاده ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684412</th>\n",
              "      <td>that is an excellent idea . when is your birth...</td>\n",
              "      <td>این یک فکر عالی است . تولد شما کی است ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684413</th>\n",
              "      <td>fine , then we will go back by train to Hambur...</td>\n",
              "      <td>خوب , بنابراین ما با قطار در سه و سی و سه دقیق...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684414</th>\n",
              "      <td>well , I think , eight o ' clock in the evenin...</td>\n",
              "      <td>خوب , من فکر میکنم , ساعت هشت بعداز ظهر کافی ا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684415</th>\n",
              "      <td>there is a train at thirty-three past six o ' ...</td>\n",
              "      <td>یک قطار برای ساعت شش و سی و سه دقیقه وجود دارد...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>684416</th>\n",
              "      <td>goodbye .</td>\n",
              "      <td>خداحافظ .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>684417 rows × 2 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:35:52.177799Z",
          "iopub.execute_input": "2021-06-30T08:35:52.178133Z",
          "iopub.status.idle": "2021-06-30T08:35:52.428850Z",
          "shell.execute_reply.started": "2021-06-30T08:35:52.178101Z",
          "shell.execute_reply": "2021-06-30T08:35:52.428012Z"
        },
        "trusted": true,
        "id": "1wEM8TayaENy"
      },
      "source": [
        "train, validation = train_test_split(df, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:35:57.204518Z",
          "iopub.execute_input": "2021-06-30T08:35:57.204842Z",
          "iopub.status.idle": "2021-06-30T08:36:03.955613Z",
          "shell.execute_reply.started": "2021-06-30T08:35:57.204812Z",
          "shell.execute_reply": "2021-06-30T08:36:03.954775Z"
        },
        "trusted": true,
        "id": "SAT7abfFaEN1"
      },
      "source": [
        "train.to_csv('train.csv', index=False)\n",
        "validation.to_csv('validation.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv-iARuufrzh"
      },
      "source": [
        "\n",
        "\n",
        "# Create dataset and dataloaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6ki-TvKJh4y"
      },
      "source": [
        "- create persian and english tokenizer functions\n",
        "- create 2 Field for persian and english\n",
        "- create training and validation data from train and validation data frames\n",
        "- build vocabulary for 2 langages with frequency threshold of 5 and maximum size of 20000\n",
        "- craete train and validation data loaders with batch size of 64\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> with help of this [tutorail](https://youtu.be/DaHAzCaXWYQ)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:36:03.957193Z",
          "iopub.execute_input": "2021-06-30T08:36:03.957638Z",
          "iopub.status.idle": "2021-06-30T08:36:04.450341Z",
          "shell.execute_reply.started": "2021-06-30T08:36:03.957596Z",
          "shell.execute_reply": "2021-06-30T08:36:04.449557Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIUIdupdaEN1",
        "outputId": "64f173bc-cddd-44c6-9a78-711bd8904a29"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:36:20.827314Z",
          "iopub.execute_input": "2021-06-30T08:36:20.827648Z",
          "iopub.status.idle": "2021-06-30T08:36:20.833727Z",
          "shell.execute_reply.started": "2021-06-30T08:36:20.827617Z",
          "shell.execute_reply": "2021-06-30T08:36:20.831607Z"
        },
        "trusted": true,
        "id": "PghcQdoBaEN4"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy.data import Field, BucketIterator, TabularDataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:36:14.422040Z",
          "iopub.execute_input": "2021-06-30T08:36:14.422410Z",
          "iopub.status.idle": "2021-06-30T08:36:14.428310Z",
          "shell.execute_reply.started": "2021-06-30T08:36:14.422375Z",
          "shell.execute_reply": "2021-06-30T08:36:14.427406Z"
        },
        "trusted": true,
        "id": "AOaMCdmCaEN3"
      },
      "source": [
        "def tokenizer_fa(text):\n",
        "  text = re.sub(\"(\\\\u200c|\\\\xad)\", \" \", text)\n",
        "  return nltk.word_tokenize(text)\n",
        "def tokenizer_eng(text):\n",
        "  return [token.lower() for token in nltk.word_tokenize(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:36:26.450213Z",
          "iopub.execute_input": "2021-06-30T08:36:26.450566Z",
          "iopub.status.idle": "2021-06-30T08:36:26.455550Z",
          "shell.execute_reply.started": "2021-06-30T08:36:26.450534Z",
          "shell.execute_reply": "2021-06-30T08:36:26.454415Z"
        },
        "trusted": true,
        "id": "1cWX9SFXaEN4"
      },
      "source": [
        "english = Field(sequential=True, use_vocab=True, tokenize=tokenizer_eng, lower=True, init_token='<SOS>', eos_token='<EOS>', batch_first=True)\n",
        "persian = Field(sequential=True, use_vocab=True, tokenize=tokenizer_fa, init_token='<SOS>', eos_token='<EOS>',  batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:36:44.705520Z",
          "iopub.execute_input": "2021-06-30T08:36:44.705869Z",
          "iopub.status.idle": "2021-06-30T08:36:44.712448Z",
          "shell.execute_reply.started": "2021-06-30T08:36:44.705837Z",
          "shell.execute_reply": "2021-06-30T08:36:44.711585Z"
        },
        "trusted": true,
        "id": "apaYIDBVaEN5"
      },
      "source": [
        "fields = {'English':('eng', english), 'Persian':('fa', persian)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:36:48.613677Z",
          "iopub.execute_input": "2021-06-30T08:36:48.613982Z",
          "iopub.status.idle": "2021-06-30T08:42:58.988149Z",
          "shell.execute_reply.started": "2021-06-30T08:36:48.613952Z",
          "shell.execute_reply": "2021-06-30T08:42:58.987318Z"
        },
        "trusted": true,
        "id": "Ud5mSlnuaEN6"
      },
      "source": [
        "train_data, validation_data = TabularDataset.splits(\n",
        "    path='',\n",
        "    train = 'train.csv',\n",
        "    validation = 'validation.csv',\n",
        "    format='csv',\n",
        "    fields=fields\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:42:58.989592Z",
          "iopub.execute_input": "2021-06-30T08:42:58.989917Z",
          "iopub.status.idle": "2021-06-30T08:43:07.250430Z",
          "shell.execute_reply.started": "2021-06-30T08:42:58.989882Z",
          "shell.execute_reply": "2021-06-30T08:43:07.249548Z"
        },
        "trusted": true,
        "id": "4Ib7g8xzaEN7"
      },
      "source": [
        "english.build_vocab(train_data,max_size= 20000, min_freq=5)\n",
        "persian.build_vocab(train_data,max_size= 20000, min_freq=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.252291Z",
          "iopub.execute_input": "2021-06-30T08:43:07.252735Z",
          "iopub.status.idle": "2021-06-30T08:43:07.258298Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.252691Z",
          "shell.execute_reply": "2021-06-30T08:43:07.257353Z"
        },
        "trusted": true,
        "id": "TUfQLe4jaEN7"
      },
      "source": [
        "train_iterator, validation_iterator = BucketIterator.splits(\n",
        "    (train_data, validation_data),\n",
        "    batch_size=64,\n",
        "    sort=False,\n",
        "    shuffle=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VdOO5GPjX6l"
      },
      "source": [
        "# Create Model\n",
        "- define positional encoding, word embedding, position wise feedforward, multihead attention modules\n",
        "- create encoder layer\n",
        "- create encoder cosist of multiple encoder layers\n",
        "- create decoder cosist of multiple decoder layers usinf torch modules\n",
        "- create transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.260920Z",
          "iopub.execute_input": "2021-06-30T08:43:07.261516Z",
          "iopub.status.idle": "2021-06-30T08:43:07.315758Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.261475Z",
          "shell.execute_reply": "2021-06-30T08:43:07.314873Z"
        },
        "trusted": true,
        "id": "ZbmDaLIpaEN8"
      },
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import  torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import math\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmS8hHbEjtO4"
      },
      "source": [
        "## positional encoding\n",
        "- embedding size of 256\n",
        "- dropout rate = 0.1\n",
        "- max length of positional encoding tensor = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.317164Z",
          "iopub.execute_input": "2021-06-30T08:43:07.317567Z",
          "iopub.status.idle": "2021-06-30T08:43:07.327350Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.317525Z",
          "shell.execute_reply": "2021-06-30T08:43:07.326212Z"
        },
        "trusted": true,
        "id": "OiQSHDL9aEN9"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 200):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        # sum of tokekn embeding and positional encoding\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8CH4Yurj8B_"
      },
      "source": [
        "## Embedding\n",
        "- map word vectors to embedding with size of 256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.328805Z",
          "iopub.execute_input": "2021-06-30T08:43:07.329186Z",
          "iopub.status.idle": "2021-06-30T08:43:07.339906Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.329150Z",
          "shell.execute_reply": "2021-06-30T08:43:07.339030Z"
        },
        "trusted": true,
        "id": "_iftI9DQaEN-"
      },
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        # token embedding * scale\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJpmgeWvkK7k"
      },
      "source": [
        "## position wise feed forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.343022Z",
          "iopub.execute_input": "2021-06-30T08:43:07.343323Z",
          "iopub.status.idle": "2021-06-30T08:43:07.351202Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.343297Z",
          "shell.execute_reply": "2021-06-30T08:43:07.350301Z"
        },
        "trusted": true,
        "id": "jUd_TTHsaEN_"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x): \n",
        "        x = self.dropout(torch.relu(self.fc_1(x))) # (batch size, seq len, hid dim)\n",
        "        x = self.fc_2(x) # (batch size, seq len, pf dim)\n",
        "        return x # (batch size, seq len, hid dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zos--9xzkX_0"
      },
      "source": [
        "## Multihead attention\n",
        "- calculate attention by scaled dot product using key, value and Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.354261Z",
          "iopub.execute_input": "2021-06-30T08:43:07.354688Z",
          "iopub.status.idle": "2021-06-30T08:43:07.367533Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.354641Z",
          "shell.execute_reply": "2021-06-30T08:43:07.366564Z"
        },
        "trusted": true,
        "id": "NWWnVvDwaEOB"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout, device):\n",
        "        super().__init__()\n",
        "        #assert hid_dim % n_heads == 0\n",
        "        self.hid_dim = hid_dim # embedding size or d_model\n",
        "        self.n_heads = n_heads  # number of heads\n",
        "        self.head_dim = hid_dim // n_heads # value dim = Query dim\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim) # Query\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim) # Key\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim) # Value\n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device) # scale for energy in scaled dot product\n",
        "  \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        Q = self.fc_q(query) # (batch size, query len, hid dim)\n",
        "        K = self.fc_k(key) # (batch size, query len, hid dim)\n",
        "        V = self.fc_v(value) # (batch size, query len, hid dim)\n",
        "     \n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # (batch size, n heads, query len, head dim)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # (batch size, n heads, key len, head dim)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3) # (batch size, n heads, value len, head dim)\n",
        "    \n",
        "        # Scaled Dot Product\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale # (batch size, n heads, query len, key len)\n",
        "        # apply mask for paddings in source sentence\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 1,  float(\"-inf\"))\n",
        "        attention = torch.softmax(energy, dim = -1) # (batch size, n heads, query len, key len)\n",
        "        x = torch.matmul(self.dropout(attention), V) # (batch size, n heads, query len, head dim)\n",
        "        x = x.permute(0, 2, 1, 3).contiguous() # (batch size, query len, n heads, head dim)\n",
        "        x = x.view(batch_size, -1, self.hid_dim) # (batch size, query len, hid dim)\n",
        "        x = self.fc_o(x) # (batch size, query len, hid dim)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaSFEGNamHtK"
      },
      "source": [
        "## creating encoder layer\n",
        "\n",
        "- multihead attention\n",
        "- add (residual) and layer Norm\n",
        "- positionwise feed forward\n",
        "- add (residual) and layer Norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.369412Z",
          "iopub.execute_input": "2021-06-30T08:43:07.369778Z",
          "iopub.status.idle": "2021-06-30T08:43:07.380824Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.369744Z",
          "shell.execute_reply": "2021-06-30T08:43:07.380012Z"
        },
        "trusted": true,
        "id": "9U6rTchXaEOF"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, \n",
        "                 hid_dim, \n",
        "                 n_heads, \n",
        "                 pf_dim,  \n",
        "                 dropout, \n",
        "                 device):\n",
        "        super().__init__()\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim, eps = 1e-05)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim,  eps = 1e-05)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        #self attention\n",
        "        _src = self.self_attention(src, src, src, src_mask)\n",
        "        \n",
        "        #dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "        #positionwise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "        #dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqZa8p12NE7z"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "- token embedding + positional encoding\n",
        "- encdoer layer (multihead attention + add and norm + position wise feed forward + add and norm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.383197Z",
          "iopub.execute_input": "2021-06-30T08:43:07.383536Z",
          "iopub.status.idle": "2021-06-30T08:43:07.394697Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.383507Z",
          "shell.execute_reply": "2021-06-30T08:43:07.393835Z"
        },
        "trusted": true,
        "id": "m9p8NspsaEOG"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 200):\n",
        "        super().__init__()\n",
        "        self.device = device\n",
        "        self.src_tok_emb = TokenEmbedding(input_dim, hid_dim)\n",
        "        self.positional_encoding = PositionalEncoding(hid_dim, dropout=dropout)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim, dropout, device) for _ in range(n_layers)])\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.positional_encoding(self.src_tok_emb(src)).to(device)\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "        return src"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mS1mGbiNJ3u"
      },
      "source": [
        "## Decoder\n",
        "- token embedding + positional encoding\n",
        "- Decoder layer of pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.395900Z",
          "iopub.execute_input": "2021-06-30T08:43:07.396298Z",
          "iopub.status.idle": "2021-06-30T08:43:07.406827Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.396261Z",
          "shell.execute_reply": "2021-06-30T08:43:07.406123Z"
        },
        "trusted": true,
        "id": "KTWeAK4MaEOI"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, trg_vocab_size, embed_size, N, heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.N = N\n",
        "        self.tgt_tok_emb = TokenEmbedding(trg_vocab_size, embed_size)\n",
        "        self.positional_encoding = PositionalEncoding(embed_size, dropout=dropout)\n",
        "        self.layers = nn.ModuleList([nn.TransformerDecoderLayer(embed_size, heads, batch_first=True, layer_norm_eps = 1e-05) for i in range(N)])\n",
        "    \n",
        "    def forward(self, tgt, e_outputs, tgt_key_padding_mask, tgt_mask):\n",
        "        tgt = self.positional_encoding(self.tgt_tok_emb(tgt)).to(device)\n",
        "        for i in range(N):\n",
        "            x = self.layers[i](tgt, e_outputs, tgt_mask = tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDwl7fNkNVGZ"
      },
      "source": [
        "## Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.407981Z",
          "iopub.execute_input": "2021-06-30T08:43:07.408542Z",
          "iopub.status.idle": "2021-06-30T08:43:07.422004Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.408506Z",
          "shell.execute_reply": "2021-06-30T08:43:07.421168Z"
        },
        "trusted": true,
        "id": "txpeXAjEaEOJ"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab, trg_vocab, d_model, N, heads, device):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab, d_model, N, heads,pf_dim=1024, dropout=0.1, device=device)\n",
        "        self.decoder = Decoder(trg_vocab, d_model, N, heads)\n",
        "        self.out = nn.Linear(d_model, trg_vocab)\n",
        "        self.softmax= nn.Softmax()\n",
        "        self.trg_pad_idx = 1\n",
        "        self.src_pad_idx =1\n",
        "        self.device = device\n",
        "\n",
        "    def make_src_mask(self, src):       \n",
        "        src_mask = (src == self.src_pad_idx)\n",
        "        return src_mask\n",
        "    \n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def create_mask(self, src, tgt):\n",
        "        tgt_seq_len = tgt.shape[1]\n",
        "        tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len)\n",
        "        tgt_padding_mask = (tgt == 1)\n",
        "        return tgt_mask ,tgt_padding_mask \n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask, tgt_padding_mask = self.create_mask(src, trg)\n",
        "        e_outputs = self.encoder(src, src_mask.unsqueeze(1).unsqueeze(2))\n",
        "        d_output = self.decoder(trg, e_outputs, tgt_padding_mask, trg_mask)\n",
        "        output = self.out(d_output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6wOXlGfNgOa"
      },
      "source": [
        "# Define a transformer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:07.423318Z",
          "iopub.execute_input": "2021-06-30T08:43:07.423802Z",
          "iopub.status.idle": "2021-06-30T08:43:10.372961Z",
          "shell.execute_reply.started": "2021-06-30T08:43:07.423767Z",
          "shell.execute_reply": "2021-06-30T08:43:10.372093Z"
        },
        "trusted": true,
        "id": "EMlYLVq0aEOK"
      },
      "source": [
        "d_model = 256\n",
        "heads = 8\n",
        "N = 3\n",
        "src_vocab = len(english.vocab)\n",
        "trg_vocab = len(persian.vocab)\n",
        "model = Transformer(src_vocab, trg_vocab, d_model, N, heads,device)\n",
        "# initialize with Xavier initialization to prevent gradient problems (vanishing or exploding)\n",
        "for p in model.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:10.381777Z",
          "iopub.execute_input": "2021-06-30T08:43:10.382319Z",
          "iopub.status.idle": "2021-06-30T08:43:10.428886Z",
          "shell.execute_reply.started": "2021-06-30T08:43:10.382284Z",
          "shell.execute_reply": "2021-06-30T08:43:10.428144Z"
        },
        "trusted": true,
        "id": "HXPTVN1oaEOY",
        "outputId": "722bfec2-6a0e-445d-b645-b7ccfafbcc7d"
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer1(\n",
              "  (encoder): Encoder(\n",
              "    (src_tok_emb): TokenEmbedding(\n",
              "      (embedding): Embedding(20004, 256)\n",
              "    )\n",
              "    (positional_encoding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
              "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tgt_tok_emb): TokenEmbedding(\n",
              "      (embedding): Embedding(20004, 256)\n",
              "    )\n",
              "    (positional_encoding): PositionalEncoding(\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (out): Linear(in_features=256, out_features=20004, bias=True)\n",
              "  (softmax): Softmax(dim=None)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLCvXHB5NpAn"
      },
      "source": [
        "# Train and validate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:10.430021Z",
          "iopub.execute_input": "2021-06-30T08:43:10.430377Z",
          "iopub.status.idle": "2021-06-30T08:43:10.436615Z",
          "shell.execute_reply.started": "2021-06-30T08:43:10.430341Z",
          "shell.execute_reply": "2021-06-30T08:43:10.435329Z"
        },
        "trusted": true,
        "id": "tPWbM8DCaEOZ"
      },
      "source": [
        "LEARNING_RATE = 0.0001\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 1) # padding index is 1 for both languages\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE,  betas=(0.9, 0.98), eps=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:10.438210Z",
          "iopub.execute_input": "2021-06-30T08:43:10.438686Z",
          "iopub.status.idle": "2021-06-30T08:43:10.454976Z",
          "shell.execute_reply.started": "2021-06-30T08:43:10.438651Z",
          "shell.execute_reply": "2021-06-30T08:43:10.454069Z"
        },
        "trusted": true,
        "id": "IbbQUqbSaEOZ"
      },
      "source": [
        "def train_model(epochs,max_iter):\n",
        "    train_loss = []\n",
        "    valid_loss = []\n",
        "    iter = 0\n",
        "    total_loss = 0\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss=0\n",
        "        for i, batch in enumerate(train_iterator):\n",
        "            model.train()\n",
        "            iter+=1\n",
        "            src = batch.eng.to(device)\n",
        "            trg = batch.fa.to(device)\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "            output = model(src, trg[:,:-1])\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)\n",
        "            loss = criterion(output, trg)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1) # clip gradient to prevent vanishing\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() \n",
        "            # validate every 200 iteration\n",
        "            if iter%200 ==0 :\n",
        "              val_loss = 0\n",
        "              model.eval()\n",
        "              with torch.no_grad():\n",
        "                for j, batch in enumerate(validation_iterator):\n",
        "                  src = batch.eng.to(device)\n",
        "                  trg = batch.fa.to(device)\n",
        "                  output = model(src, trg[:,:-1])\n",
        "                  output_dim = output.shape[-1]\n",
        "                  output = output.contiguous().view(-1, output_dim)\n",
        "                  trg = trg[:,1:].contiguous().view(-1)\n",
        "                  loss = criterion(output, trg)\n",
        "                  val_loss += loss.item()\n",
        "                # print train and validation loss\n",
        "                print(f' epoch:{epoch} - iteration:{iter} - train loss:{epoch_loss/(i+1)} - val loss:{val_loss/(j+1)}')\n",
        "                torch.save(model.cpu().state_dict(), 'final_model.pth') # saving model\n",
        "                model.to(device)\n",
        "                train_loss.append(epoch_loss/(i+1))\n",
        "                valid_loss.append(val_loss/(j+1))\n",
        "            # fininsh training if reach max iteration\n",
        "            if iter==max_iter :\n",
        "              print('finish training!')\n",
        "              break\n",
        "        if iter==max_iter:\n",
        "          break\n",
        "    return train_loss, valid_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T08:43:10.456418Z",
          "iopub.execute_input": "2021-06-30T08:43:10.456860Z",
          "iopub.status.idle": "2021-06-30T13:35:48.235629Z",
          "shell.execute_reply.started": "2021-06-30T08:43:10.456822Z",
          "shell.execute_reply": "2021-06-30T13:35:48.233794Z"
        },
        "trusted": true,
        "id": "it5slKwpaEOa",
        "outputId": "88fdfdc2-bb52-43a3-ee16-c70afb330bdd"
      },
      "source": [
        "train_loss, valid_loss = train_model(12, 68000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " epoch:0 - iteration:200 - train loss:7.789319033622742 - val loss:6.749475388660609\n",
            " epoch:0 - iteration:400 - train loss:7.138270499706269 - val loss:6.225723702439638\n",
            " epoch:0 - iteration:600 - train loss:6.771518017450968 - val loss:5.88868148571977\n",
            " epoch:0 - iteration:800 - train loss:6.522980102300644 - val loss:5.674882791198303\n",
            " epoch:0 - iteration:1000 - train loss:6.338578468322754 - val loss:5.532047980745262\n",
            " epoch:0 - iteration:1200 - train loss:6.1932370734214786 - val loss:5.405026713932786\n",
            " epoch:0 - iteration:1400 - train loss:6.073458821773529 - val loss:5.30350554902977\n",
            " epoch:0 - iteration:1600 - train loss:5.973775797188282 - val loss:5.222170840914004\n",
            " epoch:0 - iteration:1800 - train loss:5.88708287027147 - val loss:5.142074232012312\n",
            " epoch:0 - iteration:2000 - train loss:5.809064678192138 - val loss:5.076386499404907\n",
            " epoch:0 - iteration:2200 - train loss:5.741261979883367 - val loss:5.014855826012442\n",
            " epoch:0 - iteration:2400 - train loss:5.678910604317983 - val loss:4.971970972613754\n",
            " epoch:0 - iteration:2600 - train loss:5.622264566788306 - val loss:4.913317435255674\n",
            " epoch:0 - iteration:2800 - train loss:5.569333956411906 - val loss:4.863830887268636\n",
            " epoch:0 - iteration:3000 - train loss:5.520516616185506 - val loss:4.8346710833433635\n",
            " epoch:0 - iteration:3200 - train loss:5.475559928268194 - val loss:4.7786123208910505\n",
            " epoch:0 - iteration:3400 - train loss:5.433856107627644 - val loss:4.734517163873833\n",
            " epoch:0 - iteration:3600 - train loss:5.394035996066199 - val loss:4.710814571380615\n",
            " epoch:0 - iteration:3800 - train loss:5.356927118426875 - val loss:4.662494804257545\n",
            " epoch:0 - iteration:4000 - train loss:5.322128677368164 - val loss:4.631373857337738\n",
            " epoch:0 - iteration:4200 - train loss:5.288352029323578 - val loss:4.5946283563275205\n",
            " epoch:0 - iteration:4400 - train loss:5.256350123882294 - val loss:4.560925245285034\n",
            " epoch:0 - iteration:4600 - train loss:5.225597425647404 - val loss:4.541084682607205\n",
            " epoch:0 - iteration:4800 - train loss:5.19629465987285 - val loss:4.507207401222158\n",
            " epoch:0 - iteration:5000 - train loss:5.168488860321045 - val loss:4.477606235931967\n",
            " epoch:0 - iteration:5200 - train loss:5.141711283463698 - val loss:4.452999028535647\n",
            " epoch:0 - iteration:5400 - train loss:5.115566000938416 - val loss:4.422375660744783\n",
            " epoch:0 - iteration:5600 - train loss:5.090706308824675 - val loss:4.395053502555205\n",
            " epoch:0 - iteration:5800 - train loss:5.066581441451763 - val loss:4.381658380945153\n",
            " epoch:0 - iteration:6000 - train loss:5.043421626408895 - val loss:4.35512519194701\n",
            " epoch:0 - iteration:6200 - train loss:5.020949548675168 - val loss:4.327630264291139\n",
            " epoch:0 - iteration:6400 - train loss:4.999057410806418 - val loss:4.312786885511096\n",
            " epoch:0 - iteration:6600 - train loss:4.9776475793303865 - val loss:4.28247758205806\n",
            " epoch:0 - iteration:6800 - train loss:4.957561422831872 - val loss:4.267392845465758\n",
            " epoch:0 - iteration:7000 - train loss:4.937854378529957 - val loss:4.249797445368544\n",
            " epoch:0 - iteration:7200 - train loss:4.918165576126841 - val loss:4.224263680983927\n",
            " epoch:0 - iteration:7400 - train loss:4.899479957496798 - val loss:4.201026828489571\n",
            " epoch:0 - iteration:7600 - train loss:4.8807774451531865 - val loss:4.180433251033319\n",
            " epoch:0 - iteration:7800 - train loss:4.8625581023326285 - val loss:4.161675151486263\n",
            " epoch:0 - iteration:8000 - train loss:4.844919912755489 - val loss:4.1402079842915045\n",
            " epoch:0 - iteration:8200 - train loss:4.827542646919809 - val loss:4.127302968836276\n",
            " epoch:0 - iteration:8400 - train loss:4.81030963977178 - val loss:4.09895010640688\n",
            " epoch:0 - iteration:8600 - train loss:4.793562578933184 - val loss:4.0889782159127925\n",
            " epoch:0 - iteration:8800 - train loss:4.777107564590194 - val loss:4.0595774401014095\n",
            " epoch:0 - iteration:9000 - train loss:4.761288771178987 - val loss:4.042822007375343\n",
            " epoch:0 - iteration:9200 - train loss:4.745920225951982 - val loss:4.029226776818248\n",
            " epoch:0 - iteration:9400 - train loss:4.7304736996711565 - val loss:4.024093859886455\n",
            " epoch:0 - iteration:9600 - train loss:4.715380126039187 - val loss:3.9968223845847297\n",
            " epoch:1 - iteration:9800 - train loss:3.924709117071969 - val loss:3.983159885228237\n",
            " epoch:1 - iteration:10000 - train loss:3.9269197228749593 - val loss:3.9673775151511217\n",
            " epoch:1 - iteration:10200 - train loss:3.9147530941341233 - val loss:3.9556571432363206\n",
            " epoch:1 - iteration:10400 - train loss:3.9093110422934254 - val loss:3.932475208790503\n",
            " epoch:1 - iteration:10600 - train loss:3.9021870295206704 - val loss:3.919977298183976\n",
            " epoch:1 - iteration:10800 - train loss:3.8956701836687455 - val loss:3.9179375341005414\n",
            " epoch:1 - iteration:11000 - train loss:3.889631387190385 - val loss:3.888884929630244\n",
            " epoch:1 - iteration:11200 - train loss:3.8838719198438856 - val loss:3.8805116366003163\n",
            " epoch:1 - iteration:11400 - train loss:3.87611641440593 - val loss:3.8642689274850293\n",
            " epoch:1 - iteration:11600 - train loss:3.8687185508390014 - val loss:3.8593104828183895\n",
            " epoch:1 - iteration:11800 - train loss:3.861670504493275 - val loss:3.858866109357816\n",
            " epoch:1 - iteration:12000 - train loss:3.856642925061678 - val loss:3.8305228875062176\n",
            " epoch:1 - iteration:12200 - train loss:3.851386547088623 - val loss:3.8170874410700577\n",
            " epoch:1 - iteration:12400 - train loss:3.8462684816068355 - val loss:3.800793236215538\n",
            " epoch:1 - iteration:12600 - train loss:3.8407835300830233 - val loss:3.7922660718454377\n",
            " epoch:1 - iteration:12800 - train loss:3.834541776612049 - val loss:3.7840075860513704\n",
            " epoch:1 - iteration:13000 - train loss:3.828972789481834 - val loss:3.7704618300232933\n",
            " epoch:1 - iteration:13200 - train loss:3.8218902096381555 - val loss:3.7691413340167466\n",
            " epoch:1 - iteration:13400 - train loss:3.816804869317061 - val loss:3.7509113476655194\n",
            " epoch:1 - iteration:13600 - train loss:3.811515679989221 - val loss:3.741455846857802\n",
            " epoch:1 - iteration:13800 - train loss:3.8061493614333832 - val loss:3.742347336929535\n",
            " epoch:1 - iteration:14000 - train loss:3.801322507912772 - val loss:3.7199450836003383\n",
            " epoch:1 - iteration:14200 - train loss:3.795896535571156 - val loss:3.711170331117149\n",
            " epoch:1 - iteration:14400 - train loss:3.7907767464602804 - val loss:3.7059046471230337\n",
            " epoch:1 - iteration:14600 - train loss:3.785406526393028 - val loss:3.694843980307891\n",
            " epoch:1 - iteration:14800 - train loss:3.7808314600313344 - val loss:3.6820777826220077\n",
            " epoch:1 - iteration:15000 - train loss:3.7756162594196407 - val loss:3.67831511987704\n",
            " epoch:1 - iteration:15200 - train loss:3.7712174244098065 - val loss:3.668970053886699\n",
            " epoch:1 - iteration:15400 - train loss:3.766318690931642 - val loss:3.655109825535355\n",
            " epoch:1 - iteration:15600 - train loss:3.7615704491746973 - val loss:3.647857887276979\n",
            " epoch:1 - iteration:15800 - train loss:3.7571203128722033 - val loss:3.6430753641039413\n",
            " epoch:1 - iteration:16000 - train loss:3.752398426093307 - val loss:3.6362807180279884\n",
            " epoch:1 - iteration:16200 - train loss:3.748038319054665 - val loss:3.624961571827113\n",
            " epoch:1 - iteration:16400 - train loss:3.7436443961590418 - val loss:3.621552252323828\n",
            " epoch:1 - iteration:16600 - train loss:3.739271386669528 - val loss:3.619969575427403\n",
            " epoch:1 - iteration:16800 - train loss:3.734709853893373 - val loss:3.599536895306311\n",
            " epoch:1 - iteration:17000 - train loss:3.730647724313251 - val loss:3.5974496360137085\n",
            " epoch:1 - iteration:17200 - train loss:3.7262176412953796 - val loss:3.5955274949564\n",
            " epoch:1 - iteration:17400 - train loss:3.722260693338523 - val loss:3.5859424666823627\n",
            " epoch:1 - iteration:17600 - train loss:3.7182236120469145 - val loss:3.5757753332084583\n",
            " epoch:1 - iteration:17800 - train loss:3.7140378830994307 - val loss:3.5673145055770874\n",
            " epoch:1 - iteration:18000 - train loss:3.7103059251699873 - val loss:3.567940612151244\n",
            " epoch:1 - iteration:18200 - train loss:3.7064041308133318 - val loss:3.5586303410129014\n",
            " epoch:1 - iteration:18400 - train loss:3.7025091718472645 - val loss:3.5527255011496144\n",
            " epoch:1 - iteration:18600 - train loss:3.698547139712363 - val loss:3.541441086073902\n",
            " epoch:1 - iteration:18800 - train loss:3.6947369810670856 - val loss:3.534114038832834\n",
            " epoch:1 - iteration:19000 - train loss:3.690986710027059 - val loss:3.5301972638780827\n",
            " epoch:1 - iteration:19200 - train loss:3.687001680244665 - val loss:3.5244444610916568\n",
            " epoch:2 - iteration:19400 - train loss:3.3981430451075236 - val loss:3.522265701650459\n",
            " epoch:2 - iteration:19600 - train loss:3.398599056516375 - val loss:3.5236336291393386\n",
            " epoch:2 - iteration:19800 - train loss:3.404602761702104 - val loss:3.5147156078124713\n",
            " epoch:2 - iteration:20000 - train loss:3.400090044339498 - val loss:3.5104442609804813\n",
            " epoch:2 - iteration:20200 - train loss:3.3999960876766004 - val loss:3.50195656045575\n",
            " epoch:2 - iteration:20400 - train loss:3.398413938646731 - val loss:3.500871992779669\n",
            " epoch:2 - iteration:20600 - train loss:3.3962019743742764 - val loss:3.4925440759302298\n",
            " epoch:2 - iteration:20800 - train loss:3.394501923745678 - val loss:3.4922228291770008\n",
            " epoch:2 - iteration:21000 - train loss:3.394440004621233 - val loss:3.4826667928250035\n",
            " epoch:2 - iteration:21200 - train loss:3.3937174721253225 - val loss:3.4797793020711882\n",
            " epoch:2 - iteration:21400 - train loss:3.3919640221706655 - val loss:3.4773137039113267\n",
            " epoch:2 - iteration:21600 - train loss:3.390506098524053 - val loss:3.4795276971620934\n",
            " epoch:2 - iteration:21800 - train loss:3.390168062658871 - val loss:3.467506899566294\n",
            " epoch:2 - iteration:22000 - train loss:3.3887140197753904 - val loss:3.4642173029551997\n",
            " epoch:2 - iteration:22200 - train loss:3.3878763598102632 - val loss:3.4609097173280805\n",
            " epoch:2 - iteration:22400 - train loss:3.3861941563136995 - val loss:3.4509287667051654\n",
            " epoch:2 - iteration:22600 - train loss:3.3854973837155016 - val loss:3.4568414465289248\n",
            " epoch:2 - iteration:22800 - train loss:3.382729906028425 - val loss:3.44775402144851\n",
            " epoch:2 - iteration:23000 - train loss:3.3817781102498374 - val loss:3.4398534037242428\n",
            " epoch:2 - iteration:23200 - train loss:3.3803983071484143 - val loss:3.4391016728410095\n",
            " epoch:2 - iteration:23400 - train loss:3.3790363792626255 - val loss:3.431547737344403\n",
            " epoch:2 - iteration:23600 - train loss:3.3773735519935344 - val loss:3.4327247532728675\n",
            " epoch:2 - iteration:23800 - train loss:3.3763331329429542 - val loss:3.425221350482691\n",
            " epoch:2 - iteration:24000 - train loss:3.3749701334300792 - val loss:3.4196843370098935\n",
            " epoch:2 - iteration:24200 - train loss:3.3741434737889455 - val loss:3.417547568651003\n",
            " epoch:2 - iteration:24400 - train loss:3.3725266584377844 - val loss:3.4131764746157924\n",
            " epoch:2 - iteration:24600 - train loss:3.3716211171016517 - val loss:3.4128143110007882\n",
            " epoch:2 - iteration:24800 - train loss:3.3706208854108244 - val loss:3.403480683977359\n",
            " epoch:2 - iteration:25000 - train loss:3.369299308237822 - val loss:3.399976984585557\n",
            " epoch:2 - iteration:25200 - train loss:3.3673941320531506 - val loss:3.404969032679763\n",
            " epoch:2 - iteration:25400 - train loss:3.365355201853 - val loss:3.397413488860442\n",
            " epoch:2 - iteration:25600 - train loss:3.3644142762882505 - val loss:3.391811354583669\n",
            " epoch:2 - iteration:25800 - train loss:3.363319215483338 - val loss:3.3975999538029464\n",
            " epoch:2 - iteration:26000 - train loss:3.3614901477672436 - val loss:3.383453382732712\n",
            " epoch:2 - iteration:26200 - train loss:3.3598862285408186 - val loss:3.3825985752533527\n",
            " epoch:2 - iteration:26400 - train loss:3.3584034804364182 - val loss:3.376322356785569\n",
            " epoch:2 - iteration:26600 - train loss:3.3569072229035046 - val loss:3.37112794056117\n",
            " epoch:2 - iteration:26800 - train loss:3.355983932034069 - val loss:3.368696314152156\n",
            " epoch:2 - iteration:27000 - train loss:3.354735589119696 - val loss:3.3710006618054114\n",
            " epoch:2 - iteration:27200 - train loss:3.3533019441028813 - val loss:3.360741407626143\n",
            " epoch:2 - iteration:27400 - train loss:3.3520197909302505 - val loss:3.3628177362067677\n",
            " epoch:2 - iteration:27600 - train loss:3.350852432622167 - val loss:3.3539779328854284\n",
            " epoch:2 - iteration:27800 - train loss:3.349305499617816 - val loss:3.3520636427068267\n",
            " epoch:2 - iteration:28000 - train loss:3.3474245277404786 - val loss:3.3537787867483693\n",
            " epoch:2 - iteration:28200 - train loss:3.3465922092192666 - val loss:3.351631096813166\n",
            " epoch:2 - iteration:28400 - train loss:3.3455519526122046 - val loss:3.345985208270706\n",
            " epoch:2 - iteration:28600 - train loss:3.3443769220617368 - val loss:3.3427170884943456\n",
            " epoch:2 - iteration:28800 - train loss:3.343026238835919 - val loss:3.338243259002115\n",
            " epoch:3 - iteration:29000 - train loss:3.1555259971618654 - val loss:3.336854345330568\n",
            " epoch:3 - iteration:29200 - train loss:3.161563343634972 - val loss:3.333621121121344\n",
            " epoch:3 - iteration:29400 - train loss:3.155420585359846 - val loss:3.3411281748352764\n",
            " epoch:3 - iteration:29600 - train loss:3.16001433931548 - val loss:3.3299240849842535\n",
            " epoch:3 - iteration:29800 - train loss:3.16021688048904 - val loss:3.3376797607011883\n",
            " epoch:3 - iteration:30000 - train loss:3.159248193105062 - val loss:3.334404380744863\n",
            " epoch:3 - iteration:30200 - train loss:3.1602681415485887 - val loss:3.328081862503123\n",
            " epoch:3 - iteration:30400 - train loss:3.158805950039723 - val loss:3.3254266068200087\n",
            " epoch:3 - iteration:30600 - train loss:3.1633564890985904 - val loss:3.3281418764702626\n",
            " epoch:3 - iteration:30800 - train loss:3.1646655760182965 - val loss:3.3223048038571794\n",
            " epoch:3 - iteration:31000 - train loss:3.1637120044932647 - val loss:3.3256695219289476\n",
            " epoch:3 - iteration:31200 - train loss:3.1633747655601914 - val loss:3.317994912539687\n",
            " epoch:3 - iteration:31400 - train loss:3.1657919576852627 - val loss:3.3137440220217838\n",
            " epoch:3 - iteration:31600 - train loss:3.1665379795459434 - val loss:3.3118024099653014\n",
            " epoch:3 - iteration:31800 - train loss:3.1678183802580224 - val loss:3.310343431312347\n",
            " epoch:3 - iteration:32000 - train loss:3.168192967147827 - val loss:3.3145300466323566\n",
            " epoch:3 - iteration:32200 - train loss:3.167615939262218 - val loss:3.3068210062579575\n",
            " epoch:3 - iteration:32400 - train loss:3.167598258417549 - val loss:3.312563873674268\n",
            " epoch:3 - iteration:32600 - train loss:3.167741169065437 - val loss:3.306719756572046\n",
            " epoch:3 - iteration:32800 - train loss:3.167713888374863 - val loss:3.3017209587810195\n",
            " epoch:3 - iteration:33000 - train loss:3.1674878107706705 - val loss:3.293876850270779\n",
            " epoch:3 - iteration:33200 - train loss:3.16753575429751 - val loss:3.292750925438426\n",
            " epoch:3 - iteration:33400 - train loss:3.167060817170538 - val loss:3.2907062459214824\n",
            " epoch:3 - iteration:33600 - train loss:3.1673576385255844 - val loss:3.288206225466505\n",
            " epoch:3 - iteration:33800 - train loss:3.167123433853769 - val loss:3.2884063038870552\n",
            " epoch:3 - iteration:34000 - train loss:3.1665041247111994 - val loss:3.289251699625889\n",
            " epoch:3 - iteration:34200 - train loss:3.1665901736138573 - val loss:3.2799686512100363\n",
            " epoch:3 - iteration:34400 - train loss:3.167038806941175 - val loss:3.298673506540673\n",
            " epoch:3 - iteration:34600 - train loss:3.167180687225542 - val loss:3.284771674370097\n",
            " epoch:3 - iteration:34800 - train loss:3.167682802143982 - val loss:3.2783651623770456\n",
            " epoch:3 - iteration:35000 - train loss:3.1676294957764295 - val loss:3.2765683461572523\n",
            " epoch:3 - iteration:35200 - train loss:3.1670037594520055 - val loss:3.2731905614104226\n",
            " epoch:3 - iteration:35400 - train loss:3.1664847744835747 - val loss:3.2745164345358018\n",
            " epoch:3 - iteration:35600 - train loss:3.1666135662461747 - val loss:3.2681510521986774\n",
            " epoch:3 - iteration:35800 - train loss:3.166421103873408 - val loss:3.266707476500039\n",
            " epoch:3 - iteration:36000 - train loss:3.165955649559958 - val loss:3.2673014988409026\n",
            " epoch:3 - iteration:36200 - train loss:3.165895405727035 - val loss:3.2606084418073995\n",
            " epoch:3 - iteration:36400 - train loss:3.16553291304959 - val loss:3.2615470930794688\n",
            " epoch:3 - iteration:36600 - train loss:3.1655126380303145 - val loss:3.2629044044797664\n",
            " epoch:3 - iteration:36800 - train loss:3.1651319340125244 - val loss:3.259617590681415\n",
            " epoch:3 - iteration:37000 - train loss:3.1642065081669735 - val loss:3.2631987455849334\n",
            " epoch:3 - iteration:37200 - train loss:3.1641755303105077 - val loss:3.2552854832087723\n",
            " epoch:3 - iteration:37400 - train loss:3.164014308711301 - val loss:3.2533508735282397\n",
            " epoch:3 - iteration:37600 - train loss:3.163538723128573 - val loss:3.2484936417820296\n",
            " epoch:3 - iteration:37800 - train loss:3.163323297340329 - val loss:3.250173780851275\n",
            " epoch:3 - iteration:38000 - train loss:3.1631729636257644 - val loss:3.247663090162188\n",
            " epoch:3 - iteration:38200 - train loss:3.163164921420509 - val loss:3.2445385783632226\n",
            " epoch:3 - iteration:38400 - train loss:3.1628212367580946 - val loss:3.241235264216628\n",
            " epoch:4 - iteration:38600 - train loss:3.0326865911483765 - val loss:3.2430424211181212\n",
            " epoch:4 - iteration:38800 - train loss:3.022038394610087 - val loss:3.2456350429035794\n",
            " epoch:4 - iteration:39000 - train loss:3.021305281162262 - val loss:3.2421734892319294\n",
            " epoch:4 - iteration:39200 - train loss:3.027060225350516 - val loss:3.2471865729750875\n",
            " epoch:4 - iteration:39400 - train loss:3.0252017884784275 - val loss:3.2422044047685428\n",
            " epoch:4 - iteration:39600 - train loss:3.0262049410559912 - val loss:3.239407393419854\n",
            " epoch:4 - iteration:39800 - train loss:3.028472281052516 - val loss:3.241387346748994\n",
            " epoch:4 - iteration:40000 - train loss:3.031366812705994 - val loss:3.242416822576077\n",
            " epoch:4 - iteration:40200 - train loss:3.0323220537690556 - val loss:3.2483475981471694\n",
            " epoch:4 - iteration:40400 - train loss:3.032015969125848 - val loss:3.239812734193891\n",
            " epoch:4 - iteration:40600 - train loss:3.0328588937577745 - val loss:3.2362815622971435\n",
            " epoch:4 - iteration:40800 - train loss:3.0328116625288257 - val loss:3.2331062869490865\n",
            " epoch:4 - iteration:41000 - train loss:3.034113929748535 - val loss:3.2377406762025065\n",
            " epoch:4 - iteration:41200 - train loss:3.0342962418662176 - val loss:3.229170846716266\n",
            " epoch:4 - iteration:41400 - train loss:3.035310741539659 - val loss:3.231653216843293\n",
            " epoch:4 - iteration:41600 - train loss:3.0359843300234886 - val loss:3.233845606474119\n",
            " epoch:4 - iteration:41800 - train loss:3.036451368331909 - val loss:3.2276442763961364\n",
            " epoch:4 - iteration:42000 - train loss:3.0360453666278295 - val loss:3.2288704515617583\n",
            " epoch:4 - iteration:42200 - train loss:3.036869599625871 - val loss:3.2229178290500817\n",
            " epoch:4 - iteration:42400 - train loss:3.037084286274054 - val loss:3.224005507531567\n",
            " epoch:4 - iteration:42600 - train loss:3.0378663356711226 - val loss:3.222044213464327\n",
            " epoch:4 - iteration:42800 - train loss:3.0379958177167317 - val loss:3.221317626382703\n",
            " epoch:4 - iteration:43000 - train loss:3.039725097868178 - val loss:3.226110514524941\n",
            " epoch:4 - iteration:43200 - train loss:3.0394076486344033 - val loss:3.212122971989284\n",
            " epoch:4 - iteration:43400 - train loss:3.0404162819531497 - val loss:3.2162499456762155\n",
            " epoch:4 - iteration:43600 - train loss:3.040433047285267 - val loss:3.2139304051889437\n",
            " epoch:4 - iteration:43800 - train loss:3.0404922551029134 - val loss:3.2102959679665966\n",
            " epoch:4 - iteration:44000 - train loss:3.040879016009244 - val loss:3.2101927623570523\n",
            " epoch:4 - iteration:44200 - train loss:3.0414414746719496 - val loss:3.21038420022091\n",
            " epoch:4 - iteration:44400 - train loss:3.0412792901265417 - val loss:3.2051486333954\n",
            " epoch:4 - iteration:44600 - train loss:3.0416739474359105 - val loss:3.2081597911977324\n",
            " epoch:4 - iteration:44800 - train loss:3.041586482032897 - val loss:3.2042497394240903\n",
            " epoch:4 - iteration:45000 - train loss:3.041880532998305 - val loss:3.209628189612772\n",
            " epoch:4 - iteration:45200 - train loss:3.0418183239894128 - val loss:3.202986628986965\n",
            " epoch:4 - iteration:45400 - train loss:3.0424437873259835 - val loss:3.201462881141734\n",
            " epoch:4 - iteration:45600 - train loss:3.043151548378904 - val loss:3.2019044027150234\n",
            " epoch:4 - iteration:45800 - train loss:3.0434101663223685 - val loss:3.199761058236951\n",
            " epoch:4 - iteration:46000 - train loss:3.0439282286961875 - val loss:3.2033528938471716\n",
            " epoch:4 - iteration:46200 - train loss:3.044126576881904 - val loss:3.1972935620869434\n",
            " epoch:4 - iteration:46400 - train loss:3.044322764843325 - val loss:3.1909893996247622\n",
            " epoch:4 - iteration:46600 - train loss:3.0443244809280205 - val loss:3.1956948287019107\n",
            " epoch:4 - iteration:46800 - train loss:3.0443898802780245 - val loss:3.1941148290010255\n",
            " epoch:4 - iteration:47000 - train loss:3.044564730840571 - val loss:3.189164089933734\n",
            " epoch:4 - iteration:47200 - train loss:3.044346521558433 - val loss:3.191745900884967\n",
            " epoch:4 - iteration:47400 - train loss:3.044770362832573 - val loss:3.193896903501493\n",
            " epoch:4 - iteration:47600 - train loss:3.0445717208726064 - val loss:3.1836602952992803\n",
            " epoch:4 - iteration:47800 - train loss:3.044594999436409 - val loss:3.1859468413290575\n",
            " epoch:4 - iteration:48000 - train loss:3.0444654838913365 - val loss:3.183504891395569\n",
            " epoch:5 - iteration:48200 - train loss:2.923541529973348 - val loss:3.1836422588223607\n",
            " epoch:5 - iteration:48400 - train loss:2.9252802675420586 - val loss:3.189464750468174\n",
            " epoch:5 - iteration:48600 - train loss:2.920283693514372 - val loss:3.1844985286766123\n",
            " epoch:5 - iteration:48800 - train loss:2.9214322323269313 - val loss:3.1870700622273382\n",
            " epoch:5 - iteration:49000 - train loss:2.919505332674299 - val loss:3.1863841489096667\n",
            " epoch:5 - iteration:49200 - train loss:2.920256294427916 - val loss:3.1928988848891215\n",
            " epoch:5 - iteration:49400 - train loss:2.922446917365579 - val loss:3.185792281026038\n",
            " epoch:5 - iteration:49600 - train loss:2.9253260984259137 - val loss:3.192966916627973\n",
            " epoch:5 - iteration:49800 - train loss:2.927472969026708 - val loss:3.180321120547357\n",
            " epoch:5 - iteration:50000 - train loss:2.9290529070536295 - val loss:3.180586381493328\n",
            " epoch:5 - iteration:50200 - train loss:2.9296962666798785 - val loss:3.1834504963081574\n",
            " epoch:5 - iteration:50400 - train loss:2.930771073771047 - val loss:3.181308338798095\n",
            " epoch:5 - iteration:50600 - train loss:2.930647907642403 - val loss:3.179164830546513\n",
            " epoch:5 - iteration:50800 - train loss:2.9311863786037837 - val loss:3.186690725121543\n",
            " epoch:5 - iteration:51000 - train loss:2.9327672785883365 - val loss:3.186707581315085\n",
            " epoch:5 - iteration:51200 - train loss:2.9332715210488174 - val loss:3.182110410093147\n",
            " epoch:5 - iteration:51400 - train loss:2.9349501675321856 - val loss:3.1735716271623273\n",
            " epoch:5 - iteration:51600 - train loss:2.937288761619184 - val loss:3.174095873297932\n",
            " epoch:5 - iteration:51800 - train loss:2.9380674802689324 - val loss:3.1764538337137096\n",
            " epoch:5 - iteration:52000 - train loss:2.939396970195155 - val loss:3.1813835857070494\n",
            " epoch:5 - iteration:52200 - train loss:2.9397266579259393 - val loss:3.1718121325858286\n",
            " epoch:5 - iteration:52400 - train loss:2.9402885874251874 - val loss:3.175315497300335\n",
            " epoch:5 - iteration:52600 - train loss:2.9409784467260263 - val loss:3.1773783240362863\n",
            " epoch:5 - iteration:52800 - train loss:2.9415568910690553 - val loss:3.1737664802052152\n",
            " epoch:5 - iteration:53000 - train loss:2.94155724520561 - val loss:3.1668504135630955\n",
            " epoch:5 - iteration:53200 - train loss:2.9427047631306014 - val loss:3.1650269388038423\n",
            " epoch:5 - iteration:53400 - train loss:2.943070192924608 - val loss:3.1663379524355735\n",
            " epoch:5 - iteration:53600 - train loss:2.9437570671186055 - val loss:3.1657683080601915\n",
            " epoch:5 - iteration:53800 - train loss:2.9445300197601316 - val loss:3.1653728297937698\n",
            " epoch:5 - iteration:54000 - train loss:2.9450616564243397 - val loss:3.1617894803252176\n",
            " epoch:5 - iteration:54200 - train loss:2.946311717366976 - val loss:3.165325713380475\n",
            " epoch:5 - iteration:54400 - train loss:2.946676274827752 - val loss:3.164748014913541\n",
            " epoch:5 - iteration:54600 - train loss:2.9469575385237294 - val loss:3.1627545922716087\n",
            " epoch:5 - iteration:54800 - train loss:2.9473577003621876 - val loss:3.160175565247224\n",
            " epoch:5 - iteration:55000 - train loss:2.948313998863914 - val loss:3.1606560990075083\n",
            " epoch:5 - iteration:55200 - train loss:2.949104341028436 - val loss:3.1638525231976375\n",
            " epoch:5 - iteration:55400 - train loss:2.949322364354871 - val loss:3.158174291726585\n",
            " epoch:5 - iteration:55600 - train loss:2.949542319096849 - val loss:3.1521725964323384\n",
            " epoch:5 - iteration:55800 - train loss:2.950064254008986 - val loss:3.1510420629911335\n",
            " epoch:5 - iteration:56000 - train loss:2.9506996120876736 - val loss:3.1541231699078995\n",
            " epoch:5 - iteration:56200 - train loss:2.9511356582287296 - val loss:3.1473171352226044\n",
            " epoch:5 - iteration:56400 - train loss:2.9513901146373 - val loss:3.1603668932602784\n",
            " epoch:5 - iteration:56600 - train loss:2.9521076055824933 - val loss:3.1530350607132243\n",
            " epoch:5 - iteration:56800 - train loss:2.952488492503977 - val loss:3.157820143877903\n",
            " epoch:5 - iteration:57000 - train loss:2.9528845368774843 - val loss:3.144271211312196\n",
            " epoch:5 - iteration:57200 - train loss:2.953270592676378 - val loss:3.1459490305909488\n",
            " epoch:5 - iteration:57400 - train loss:2.953790710865648 - val loss:3.1462171264897996\n",
            " epoch:5 - iteration:57600 - train loss:2.954425173334207 - val loss:3.143686624108074\n",
            " epoch:6 - iteration:57800 - train loss:2.823850464820862 - val loss:3.1616910350656955\n",
            " epoch:6 - iteration:58000 - train loss:2.8220962505340577 - val loss:3.147708469684993\n",
            " epoch:6 - iteration:58200 - train loss:2.8240420002407496 - val loss:3.148447980836173\n",
            " epoch:6 - iteration:58400 - train loss:2.8308386674294104 - val loss:3.1504529614314856\n",
            " epoch:6 - iteration:58600 - train loss:2.8368671366747686 - val loss:3.152620918728481\n",
            " epoch:6 - iteration:58800 - train loss:2.8412416126614524 - val loss:3.155181054534199\n",
            " epoch:6 - iteration:59000 - train loss:2.840530825614929 - val loss:3.151236467940785\n",
            " epoch:6 - iteration:59200 - train loss:2.84304710223757 - val loss:3.153819499951657\n",
            " epoch:6 - iteration:59400 - train loss:2.844769316875573 - val loss:3.1573811292648317\n",
            " epoch:6 - iteration:59600 - train loss:2.8452886515694695 - val loss:3.1481943286467935\n",
            " epoch:6 - iteration:59800 - train loss:2.848425571744035 - val loss:3.1497371789450956\n",
            " epoch:6 - iteration:60000 - train loss:2.8492496740553115 - val loss:3.1501836326634773\n",
            " epoch:6 - iteration:60200 - train loss:2.8509277787500498 - val loss:3.1540132622852504\n",
            " epoch:6 - iteration:60400 - train loss:2.853637134803916 - val loss:3.1475032868786395\n",
            " epoch:6 - iteration:60600 - train loss:2.8559737330988835 - val loss:3.1516473409171417\n",
            " epoch:6 - iteration:60800 - train loss:2.8563766162121884 - val loss:3.1443091443765945\n",
            " epoch:6 - iteration:61000 - train loss:2.85871522632012 - val loss:3.1518130373731954\n",
            " epoch:6 - iteration:61200 - train loss:2.8592954747573187 - val loss:3.155305512820449\n",
            " epoch:6 - iteration:61400 - train loss:2.8609682257534708 - val loss:3.1502085888497184\n",
            " epoch:6 - iteration:61600 - train loss:2.862404559494613 - val loss:3.1427213098401223\n",
            " epoch:6 - iteration:61800 - train loss:2.863080050444897 - val loss:3.14573187226447\n",
            " epoch:6 - iteration:62000 - train loss:2.8639071247998404 - val loss:3.1394364216617334\n",
            " epoch:6 - iteration:62200 - train loss:2.8642705560534187 - val loss:3.139242692082842\n",
            " epoch:6 - iteration:62400 - train loss:2.865526925774031 - val loss:3.1369513580732256\n",
            " epoch:6 - iteration:62600 - train loss:2.8669375158093637 - val loss:3.138388376592476\n",
            " epoch:6 - iteration:62800 - train loss:2.8677954919267408 - val loss:3.135264046392708\n",
            " epoch:6 - iteration:63000 - train loss:2.8688850284303937 - val loss:3.138099757310386\n",
            " epoch:6 - iteration:63200 - train loss:2.8698252734787966 - val loss:3.140937998584498\n",
            " epoch:6 - iteration:63400 - train loss:2.8699751485554517 - val loss:3.1398426588450636\n",
            " epoch:6 - iteration:63600 - train loss:2.870669861899482 - val loss:3.135684279415095\n",
            " epoch:6 - iteration:63800 - train loss:2.871774299164449 - val loss:3.13076710344475\n",
            " epoch:6 - iteration:64000 - train loss:2.8731477140426636 - val loss:3.1281846641380096\n",
            " epoch:6 - iteration:64200 - train loss:2.8740870152702627 - val loss:3.1400393129509188\n",
            " epoch:6 - iteration:64400 - train loss:2.87463264167757 - val loss:3.130625723901196\n",
            " epoch:6 - iteration:64600 - train loss:2.875617755799398 - val loss:3.1278817499909444\n",
            " epoch:6 - iteration:64800 - train loss:2.8760300050221437 - val loss:3.1259327048453214\n",
            " epoch:6 - iteration:65000 - train loss:2.8765429486241834 - val loss:3.1264631605593958\n",
            " epoch:6 - iteration:65200 - train loss:2.8772323757850082 - val loss:3.1273836245046596\n",
            " epoch:6 - iteration:65400 - train loss:2.878165019166236 - val loss:3.1312540885444\n",
            " epoch:6 - iteration:65600 - train loss:2.878452920184773 - val loss:3.1254672507259333\n",
            " epoch:6 - iteration:65800 - train loss:2.8790128600671423 - val loss:3.122992807236787\n",
            " epoch:6 - iteration:66000 - train loss:2.879759688724171 - val loss:3.1258311193680095\n",
            " epoch:6 - iteration:66200 - train loss:2.8800146355995766 - val loss:3.121282180893087\n",
            " epoch:6 - iteration:66400 - train loss:2.8807833612034086 - val loss:3.123922013567987\n",
            " epoch:6 - iteration:66600 - train loss:2.88157110437835 - val loss:3.121906769387076\n",
            " epoch:6 - iteration:66800 - train loss:2.881933255617131 - val loss:3.1230914681871362\n",
            " epoch:6 - iteration:67000 - train loss:2.8823708613885417 - val loss:3.1196995621529693\n",
            " epoch:6 - iteration:67200 - train loss:2.8831581746964225 - val loss:3.11426898831519\n",
            " epoch:7 - iteration:67400 - train loss:2.7543926143646242 - val loss:3.1174099289368247\n",
            " epoch:7 - iteration:67600 - train loss:2.7416889550950794 - val loss:3.125585963570069\n",
            " epoch:7 - iteration:67800 - train loss:2.7537329600839056 - val loss:3.125825242015803\n",
            " epoch:7 - iteration:68000 - train loss:2.760568398666382 - val loss:3.1345517670996834\n",
            "finish training!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:35:48.238597Z",
          "iopub.execute_input": "2021-06-30T13:35:48.238953Z",
          "iopub.status.idle": "2021-06-30T13:35:48.516519Z",
          "shell.execute_reply.started": "2021-06-30T13:35:48.238913Z",
          "shell.execute_reply": "2021-06-30T13:35:48.515689Z"
        },
        "trusted": true,
        "id": "71X5FFW7aEOb",
        "outputId": "2d74226a-eba2-438b-b4d5-5383f8a5b8cf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
        "plt.title('Loss per iteration')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.plot(train_loss, label='train')\n",
        "plt.plot(valid_loss, label='validation')\n",
        "plt.xticks(rotation=45)\n",
        "locs, labels = plt.xticks()\n",
        "labels = [(int(item))*200 for item in locs]\n",
        "plt.xticks(locs, labels)\n",
        "plt.xlim(xmin=-0.9, xmax = (len(train_loss)+1))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzZKIz0hNvtp"
      },
      "source": [
        "# Test and evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:35:48.517760Z",
          "iopub.execute_input": "2021-06-30T13:35:48.518098Z",
          "iopub.status.idle": "2021-06-30T13:35:48.544963Z",
          "shell.execute_reply.started": "2021-06-30T13:35:48.518050Z",
          "shell.execute_reply": "2021-06-30T13:35:48.544274Z"
        },
        "trusted": true,
        "id": "K_UZT-mwaEOc"
      },
      "source": [
        "test_text_fa0 = open('./Test/test.fa0', encoding='utf8').read().splitlines()\n",
        "test_text_fa1 = open('./Test/test.fa1', encoding='utf8').read().splitlines()\n",
        "test_text_fa2 = open('./Test/test.fa2', encoding='utf8').read().splitlines()\n",
        "test_text_fa3 = open('./Test/test.fa3', encoding='utf8').read().splitlines()\n",
        "test_text_eng =  open('./Test/test.en', encoding='utf8').read().splitlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8U4vV8OXkPV"
      },
      "source": [
        "## Translation Function\n",
        "- based on greedy search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:35:48.547600Z",
          "iopub.execute_input": "2021-06-30T13:35:48.547843Z",
          "iopub.status.idle": "2021-06-30T13:35:48.556350Z",
          "shell.execute_reply.started": "2021-06-30T13:35:48.547818Z",
          "shell.execute_reply": "2021-06-30T13:35:48.555513Z"
        },
        "trusted": true,
        "id": "Zd13QmbxaEOc"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):  \n",
        "    model.eval()\n",
        "    tokens = nltk.word_tokenize(sentence.lower()) # tokenize source sentence\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token] # add <SOS> and <EOS>\n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens] # map tokens to index in source vocab\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "    src_mask = model.make_src_mask(src_tensor) # make mask for if there is padding\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask) # output of encoder\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]] # strat translation with <SOS> token\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask, tgt_padding_mask = model.create_mask(src_tensor, trg_tensor) \n",
        "        with torch.no_grad():\n",
        "          output = model.decoder(trg_tensor, enc_src, tgt_padding_mask, trg_mask)\n",
        "          output = model.out(output)   \n",
        "        pred_token = output.argmax(2)[:,-1].item() # select maximum probable token due to gready search\n",
        "        trg_indexes.append(pred_token)\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
        "    return trg_tokens[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGiSqIPpV2Sl"
      },
      "source": [
        "## test translate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:35:48.557587Z",
          "iopub.execute_input": "2021-06-30T13:35:48.558211Z",
          "iopub.status.idle": "2021-06-30T13:35:48.575458Z",
          "shell.execute_reply.started": "2021-06-30T13:35:48.558173Z",
          "shell.execute_reply": "2021-06-30T13:35:48.574218Z"
        },
        "trusted": true,
        "id": "_cwmYRfGaEOd",
        "outputId": "3103a3a1-9ded-4841-cfd7-52bc77083ec9"
      },
      "source": [
        "src = test_text_eng[43]\n",
        "print(src)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I did not understand , what you said about the hotel .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:35:48.579939Z",
          "iopub.execute_input": "2021-06-30T13:35:48.580268Z",
          "iopub.status.idle": "2021-06-30T13:35:48.674067Z",
          "shell.execute_reply.started": "2021-06-30T13:35:48.580241Z",
          "shell.execute_reply": "2021-06-30T13:35:48.673081Z"
        },
        "trusted": true,
        "id": "yHq2VQuuaEOd",
        "outputId": "44d04e9a-d82c-471e-80af-a338e9bbb42a"
      },
      "source": [
        "trg  = translate_sentence(src, english, persian, model, device, max_len = 50)\n",
        "print(\" \".join(trg[:-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "من گفتم , شما درباره آنچه که هتل را درک نمی کنم .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnM50p7SV5jg"
      },
      "source": [
        "## calculate BLUE and NIST score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:35:48.675630Z",
          "iopub.execute_input": "2021-06-30T13:35:48.675989Z",
          "iopub.status.idle": "2021-06-30T13:35:48.680279Z",
          "shell.execute_reply.started": "2021-06-30T13:35:48.675951Z",
          "shell.execute_reply": "2021-06-30T13:35:48.679190Z"
        },
        "trusted": true,
        "id": "2a5maDvLaEOe"
      },
      "source": [
        "from nltk.translate import nist_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:36:05.423891Z",
          "iopub.execute_input": "2021-06-30T13:36:05.424226Z",
          "iopub.status.idle": "2021-06-30T13:36:05.616811Z",
          "shell.execute_reply.started": "2021-06-30T13:36:05.424194Z",
          "shell.execute_reply": "2021-06-30T13:36:05.616059Z"
        },
        "trusted": true,
        "id": "vJiDQ80SaEOe"
      },
      "source": [
        "test_sentences =  [sentence for sentence in test_text_eng]\n",
        "refrences = [[tokenizer_fa(test_text_fa0[i]), tokenizer_fa(test_text_fa1[i]), tokenizer_fa(test_text_fa2[i]), tokenizer_fa(test_text_fa3[i])] for i in range(len(test_text_fa3))]\n",
        "test_results=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:36:05.962374Z",
          "iopub.execute_input": "2021-06-30T13:36:05.962641Z",
          "iopub.status.idle": "2021-06-30T13:36:16.429207Z",
          "shell.execute_reply.started": "2021-06-30T13:36:05.962616Z",
          "shell.execute_reply": "2021-06-30T13:36:16.428325Z"
        },
        "trusted": true,
        "id": "rBTIqX01aEOf",
        "outputId": "c48d23fa-f6fc-4f15-f98e-6c7d877474af"
      },
      "source": [
        "blue_scores = []\n",
        "Nist_score = []\n",
        "for i in range(len(test_sentences)):\n",
        "  src = test_sentences[i]\n",
        "  trg  = translate_sentence(src, english, persian, model, device, max_len = 50)\n",
        "  test_results.append(trg[:-1])\n",
        "  blue_scores.append(nltk.translate.bleu_score.corpus_bleu([refrences[i]], [trg[:-1]]))\n",
        "  try:\n",
        "    Nist_score.append(nist_score.corpus_nist([refrences[i]], [trg[:-1]]))\n",
        "  except ZeroDivisionError:\n",
        "    Nist_score.append(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/opt/conda/lib/python3.7/site-packages/nltk/translate/bleu_score.py:516: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:36:16.430572Z",
          "iopub.execute_input": "2021-06-30T13:36:16.430898Z",
          "iopub.status.idle": "2021-06-30T13:36:16.436156Z",
          "shell.execute_reply.started": "2021-06-30T13:36:16.430862Z",
          "shell.execute_reply": "2021-06-30T13:36:16.435341Z"
        },
        "trusted": true,
        "id": "82nxgwCJaEOf",
        "outputId": "77494b0e-b903-4cd4-e7e3-9cbb2559b366"
      },
      "source": [
        "print(f'mean BLUE: {np.mean(blue_scores)}')\n",
        "print(f'mean NIST: {np.mean(Nist_score)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean BLUE: 0.14630631296923563\n",
            "mean NIST: 1.9501294201285504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THUNOL0kV_UO"
      },
      "source": [
        "## Some of translations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-06-30T13:38:05.459045Z",
          "iopub.execute_input": "2021-06-30T13:38:05.459401Z",
          "iopub.status.idle": "2021-06-30T13:38:05.473840Z",
          "shell.execute_reply.started": "2021-06-30T13:38:05.459365Z",
          "shell.execute_reply": "2021-06-30T13:38:05.472585Z"
        },
        "trusted": true,
        "id": "s0GU_AnDaEOg",
        "outputId": "c602e61a-86c3-4f1d-f0c4-4141f595bb65"
      },
      "source": [
        "for i in range(50):\n",
        "    sentence = test_sentences[i]\n",
        "    translation = \" \".join(test_results[i])\n",
        "    print(f'{i}: original sentence: {sentence} \\ntranslation: {translation}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0: original sentence: hello , do we drive together to Hanover on the twenty-eighth of March ? \n",
            "translation: سلام , ما در مارس با یکدیگر به هانوور حرکت خواهیم کرد ?\n",
            "1: original sentence: it is more comfortable by train . \n",
            "translation: قطار راحت تر است .\n",
            "2: original sentence: do you go by car and I go by train ? \n",
            "translation: و من با ماشین قطار می روم ?\n",
            "3: original sentence: I would like to go by train . and what would you like ? \n",
            "translation: و من دوست دارم آموزش می خواهم به شما بروم .\n",
            "4: original sentence: if we take the $I-$C-$E train at six past seven , we will arrive at twenty-five past eight . \n",
            "translation: اگر قطار <unk> را در ساعت هفت و بیست و شش و پنج و هفت و هفت تا بیست و هفت دلار در آخر هفته گذشته به شما آموزش خواهیم رسید .\n",
            "5: original sentence: which cafe ? \n",
            "translation: که کافه است\n",
            "6: original sentence: the cafe at platform fourteen . \n",
            "translation: 14 - در کافه کافی در کافه .\n",
            "7: original sentence: in any case a cheap hotel . \n",
            "translation: در هر صورت ارزان قیمت در هر صورت ارزان .\n",
            "8: original sentence: what did you say , please ? \n",
            "translation: لطفا چی ?\n",
            "9: original sentence: and how much is a single room ? \n",
            "translation: و چقدر هم هست ?\n",
            "10: original sentence: we can take a taxi from the station to the hotel . \n",
            "translation: ما می توانیم از یک هتل را از یک تاکسی بگیریم .\n",
            "11: original sentence: at which hotel do you want to reserve a room now and how much is a single room ? \n",
            "translation: حالا شما یک اتاق هتل دارید که چقدر می خواهید اتاق رزرو شده و یک اتاق است ?\n",
            "12: original sentence: okay , should we drive back on Friday evening ? \n",
            "translation: باشه , ما باید جمعه را دوباره به عقب بیاندازیم ?\n",
            "13: original sentence: I think we rather drive back at thirty-three past nine then we will arrive at Hamburg at fifty-two past ten . \n",
            "translation: من فکر میکنم نه و نه به عقب نشینی در ساعت نه و سپس به هامبورگ خواهیم رسید .\n",
            "14: original sentence: fine and don't forget your swimming stuff , maybe we can go swimming together . \n",
            "translation: خوب است , شاید ما نمی توانیم شنا کردن را فراموش کنیم , و شنا کردن را فراموش کنیم .\n",
            "15: original sentence: yes . when and where do we want to meet ? \n",
            "translation: بله , کجا میتوانیم ملاقات کنیم ? بله .\n",
            "16: original sentence: I prefer the plane . \n",
            "translation: من هواپیما را ترجیح میدهم .\n",
            "17: original sentence: a good idea . then we will meet at the airport tomorrow . \n",
            "translation: پس فردا همدیگر را در فرودگاه ملاقات خواهیم کرد .\n",
            "18: original sentence: no idea . we will see . it does not matter . \n",
            "translation: ما این ایده را نمی بینیم . نه .\n",
            "19: original sentence: good . let us meet at nine o'clock . hopefully the plane won't be hijacked tomorrow . \n",
            "translation: امید دیدار نه . فردا , فردا , نه . فردا , با هواپیما ملاقات کنیم .\n",
            "20: original sentence: I have already booked two rooms at the Gr\"unschnabel . \n",
            "translation: من قبلا دو اتاق رزرو شده ام را در ساعت رزرو کرده ام . ''\n",
            "21: original sentence: what did you say ? \n",
            "translation: شما چه گفتید ?\n",
            "22: original sentence: yes . we have two rooms at the Gr\"unschnabel . I will reserve a taxi right now . \n",
            "translation: بله , من الان دو اتاق دارم . درست همین الان در اتاق یک تاکسی ذخیره می کنم . ''\n",
            "23: original sentence: what is planned for the evening ? \n",
            "translation: برنامه ریزی برای عصر چیست ?\n",
            "24: original sentence: a good idea . I have heard , Phantom of the opera is supposed to be played . \n",
            "translation: فکر می کنم که این ایده خوبی است که باید اجرا شود , خوب باشد .\n",
            "25: original sentence: fine . I think we have arranged everything . then we will meet tomorrow . \n",
            "translation: خوب است . فکر میکنم ما فردا همدیگر را ملاقات کنیم .\n",
            "26: original sentence: hello . we have to talk about our trip to Hanover . \n",
            "translation: سلام . ما باید درباره سفر به هانوور صحبت کنیم .\n",
            "27: original sentence: right . we will be at the Expo two thousand in Hanover on the fourth and fifth of September . \n",
            "translation: ما در پنجم سپتامبر در دو هزار و چهارم سپتامبر در هانوور خواهیم بود .\n",
            "28: original sentence: I have already booked a flight . \n",
            "translation: من قبلا یک پرواز رزرو شده است .\n",
            "29: original sentence: we will set off at a quarter past eight and arrive at Hanover at twelve o'clock . \n",
            "translation: ما ساعت دوازده و نیم به هانوور خواهیم رسید و در ساعت هشت و در ساعت در ساعت هشت و نیم به هانوور خواهیم رسید .\n",
            "30: original sentence: we will have to meet at the airport at seven o'clock . \n",
            "translation: ما باید در فرودگاه <unk> ملاقات کنیم .\n",
            "31: original sentence: we arrive at Hanover at twelve o'clock midday . \n",
            "translation: ما در ساعت دوازده ظهر به هانوور میرسد .\n",
            "32: original sentence: fine . which hotel do you have in mind ? \n",
            "translation: خوب است ? شما چه هتل دارید ?\n",
            "33: original sentence: the Intercontinental is my favourite hotel in Hanover . \n",
            "translation: محبوب من در هتل های قاره ای در هانوور به هانوور می رود .\n",
            "34: original sentence: thank you . how do we go back again to Hamburg ? \n",
            "translation: ما دوباره به هامبورگ <unk> ? متشکرم .\n",
            "35: original sentence: we will go back by train on the fifth of September . \n",
            "translation: ما در پنجم سپتامبر به سمت قطار خواهیم رفت .\n",
            "36: original sentence: the best thing is we meet at the train station at eight o'clock . \n",
            "translation: بهترین چیز در ایستگاه قطار در ساعت هشت قطار در <unk> است .\n",
            "37: original sentence: exactly . the train leaves Hanover at six minutes after eight . \n",
            "translation: دقیقا بعد از ساعت هشت دقیقه , قطار در هانوور .\n",
            "38: original sentence: we leave Hanover at eight o'clock and arrive at Hamburg at half past nine . \n",
            "translation: ما نه و نیم به هانوور می رسند و نه و نیم به هانوور می رویم .\n",
            "39: original sentence: goodbye . \n",
            "translation: خداحافظ .\n",
            "40: original sentence: I would prefer to fly . \n",
            "translation: من ترجیح میدهم .\n",
            "41: original sentence: yes , there is a flight at a quarter past nine . \n",
            "translation: بله , یک چهارم در پرواز در یک چهارم وجود دارد .\n",
            "42: original sentence: the plane arrives in Hanover at twenty-five past twelve . \n",
            "translation: بیست و پنج و پنج دقیقه به هانوور میرسد .\n",
            "43: original sentence: I did not understand , what you said about the hotel . \n",
            "translation: من گفتم , شما درباره آنچه که هتل را درک نمی کنم .\n",
            "44: original sentence: yes , would you please book two rooms . \n",
            "translation: بله , دو اتاق کتاب را لطفا .\n",
            "45: original sentence: the single room costs a hundred Deutsch-marks . did I understand you right ? \n",
            "translation: من شما یک اتاق دارید ? شما متوجه شدم که هزینه های شما یک اتاق را درک می کنید .\n",
            "46: original sentence: where is this hotel ? \n",
            "translation: این هتل کجا است ?\n",
            "47: original sentence: when do we meet ? \n",
            "translation: چه زمانی ملاقات میکنیم ?\n",
            "48: original sentence: yes , would you please book this hotel . \n",
            "translation: بله , شما را می کنید , لطفا این کتاب را اینجا رزرو کنید .\n",
            "49: original sentence: please repeat this once again . \n",
            "translation: لطفا دوباره تکرار کنید .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKHRs1FTaEOh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}